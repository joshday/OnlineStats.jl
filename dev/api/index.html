<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · OnlineStats Docs</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-72795550-5', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="OnlineStats Docs logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Welcome!</a></li><li><a class="tocitem" href="../stats_and_models/">Statistics and Models</a></li><li><a class="tocitem" href="../bigdata/">Big Data</a></li><li><a class="tocitem" href="../dataviz/">Data Viz</a></li><li><a class="tocitem" href="../collections/">Collections of Stats</a></li><li><a class="tocitem" href="../howfitworks/">How <code>fit!</code> Works</a></li><li><a class="tocitem" href="../weights/">Weights</a></li><li class="is-active"><a class="tocitem" href>API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/joshday/OnlineStats.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h1><ul><li><a href="#OnlineStats.ADADELTA"><code>OnlineStats.ADADELTA</code></a></li><li><a href="#OnlineStats.ADAGRAD"><code>OnlineStats.ADAGRAD</code></a></li><li><a href="#OnlineStats.ADAM"><code>OnlineStats.ADAM</code></a></li><li><a href="#OnlineStats.ADAMAX"><code>OnlineStats.ADAMAX</code></a></li><li><a href="#OnlineStats.Ash"><code>OnlineStats.Ash</code></a></li><li><a href="#OnlineStats.AutoCov"><code>OnlineStats.AutoCov</code></a></li><li><a href="#OnlineStats.BiasVec"><code>OnlineStats.BiasVec</code></a></li><li><a href="#OnlineStats.Bootstrap"><code>OnlineStats.Bootstrap</code></a></li><li><a href="#OnlineStats.CCIPCA"><code>OnlineStats.CCIPCA</code></a></li><li><a href="#OnlineStats.CallFun"><code>OnlineStats.CallFun</code></a></li><li><a href="#OnlineStats.Cluster"><code>OnlineStats.Cluster</code></a></li><li><a href="#OnlineStats.Diff"><code>OnlineStats.Diff</code></a></li><li><a href="#OnlineStats.ExpandingHist"><code>OnlineStats.ExpandingHist</code></a></li><li><a href="#OnlineStats.FastForest"><code>OnlineStats.FastForest</code></a></li><li><a href="#OnlineStats.FastTree"><code>OnlineStats.FastTree</code></a></li><li><a href="#OnlineStats.FitBeta"><code>OnlineStats.FitBeta</code></a></li><li><a href="#OnlineStats.FitCauchy"><code>OnlineStats.FitCauchy</code></a></li><li><a href="#OnlineStats.FitGamma"><code>OnlineStats.FitGamma</code></a></li><li><a href="#OnlineStats.FitLogNormal"><code>OnlineStats.FitLogNormal</code></a></li><li><a href="#OnlineStats.FitMultinomial"><code>OnlineStats.FitMultinomial</code></a></li><li><a href="#OnlineStats.FitMvNormal"><code>OnlineStats.FitMvNormal</code></a></li><li><a href="#OnlineStats.FitNormal"><code>OnlineStats.FitNormal</code></a></li><li><a href="#OnlineStats.HeatMap"><code>OnlineStats.HeatMap</code></a></li><li><a href="#OnlineStats.Hist"><code>OnlineStats.Hist</code></a></li><li><a href="#OnlineStats.HyperLogLog"><code>OnlineStats.HyperLogLog</code></a></li><li><a href="#OnlineStats.IndexedPartition"><code>OnlineStats.IndexedPartition</code></a></li><li><a href="#OnlineStats.KHist"><code>OnlineStats.KHist</code></a></li><li><a href="#OnlineStats.KHist2D"><code>OnlineStats.KHist2D</code></a></li><li><a href="#OnlineStats.KIndexedPartition"><code>OnlineStats.KIndexedPartition</code></a></li><li><a href="#OnlineStats.KMeans"><code>OnlineStats.KMeans</code></a></li><li><a href="#OnlineStats.KahanMean"><code>OnlineStats.KahanMean</code></a></li><li><a href="#OnlineStats.KahanSum"><code>OnlineStats.KahanSum</code></a></li><li><a href="#OnlineStats.KahanVariance"><code>OnlineStats.KahanVariance</code></a></li><li><a href="#OnlineStats.Lag"><code>OnlineStats.Lag</code></a></li><li><a href="#OnlineStats.LinReg"><code>OnlineStats.LinReg</code></a></li><li><a href="#OnlineStats.LinRegBuilder"><code>OnlineStats.LinRegBuilder</code></a></li><li><a href="#OnlineStats.MSPI"><code>OnlineStats.MSPI</code></a></li><li><a href="#OnlineStats.Mosaic"><code>OnlineStats.Mosaic</code></a></li><li><a href="#OnlineStats.MovingTimeWindow"><code>OnlineStats.MovingTimeWindow</code></a></li><li><a href="#OnlineStats.MovingWindow"><code>OnlineStats.MovingWindow</code></a></li><li><a href="#OnlineStats.NBClassifier"><code>OnlineStats.NBClassifier</code></a></li><li><a href="#OnlineStats.OMAP"><code>OnlineStats.OMAP</code></a></li><li><a href="#OnlineStats.OMAS"><code>OnlineStats.OMAS</code></a></li><li><a href="#OnlineStats.OrderStats"><code>OnlineStats.OrderStats</code></a></li><li><a href="#OnlineStats.P2Quantile"><code>OnlineStats.P2Quantile</code></a></li><li><a href="#OnlineStats.Partition"><code>OnlineStats.Partition</code></a></li><li><a href="#OnlineStats.ProbMap"><code>OnlineStats.ProbMap</code></a></li><li><a href="#OnlineStats.Quantile"><code>OnlineStats.Quantile</code></a></li><li><a href="#OnlineStats.RMSPROP"><code>OnlineStats.RMSPROP</code></a></li><li><a href="#OnlineStats.ReservoirSample"><code>OnlineStats.ReservoirSample</code></a></li><li><a href="#OnlineStats.SGD"><code>OnlineStats.SGD</code></a></li><li><a href="#OnlineStats.StatLag"><code>OnlineStats.StatLag</code></a></li><li><a href="#OnlineStats.StatLearn"><code>OnlineStats.StatLearn</code></a></li><li><a href="#OnlineStatsBase.CountMap"><code>OnlineStatsBase.CountMap</code></a></li><li><a href="#OnlineStatsBase.CountMissing"><code>OnlineStatsBase.CountMissing</code></a></li><li><a href="#OnlineStatsBase.Counter"><code>OnlineStatsBase.Counter</code></a></li><li><a href="#OnlineStatsBase.CovMatrix"><code>OnlineStatsBase.CovMatrix</code></a></li><li><a href="../weights/#OnlineStatsBase.EqualWeight"><code>OnlineStatsBase.EqualWeight</code></a></li><li><a href="../weights/#OnlineStatsBase.ExponentialWeight"><code>OnlineStatsBase.ExponentialWeight</code></a></li><li><a href="#OnlineStatsBase.FTSeries"><code>OnlineStatsBase.FTSeries</code></a></li><li><a href="#OnlineStatsBase.Group"><code>OnlineStatsBase.Group</code></a></li><li><a href="#OnlineStatsBase.GroupBy"><code>OnlineStatsBase.GroupBy</code></a></li><li><a href="../weights/#OnlineStatsBase.HarmonicWeight"><code>OnlineStatsBase.HarmonicWeight</code></a></li><li><a href="../weights/#OnlineStatsBase.LearningRate"><code>OnlineStatsBase.LearningRate</code></a></li><li><a href="../weights/#OnlineStatsBase.LearningRate2"><code>OnlineStatsBase.LearningRate2</code></a></li><li><a href="../weights/#OnlineStatsBase.McclainWeight"><code>OnlineStatsBase.McclainWeight</code></a></li><li><a href="#OnlineStatsBase.Mean"><code>OnlineStatsBase.Mean</code></a></li><li><a href="#OnlineStatsBase.Moments"><code>OnlineStatsBase.Moments</code></a></li><li><a href="#OnlineStatsBase.Series"><code>OnlineStatsBase.Series</code></a></li><li><a href="#OnlineStatsBase.Sum"><code>OnlineStatsBase.Sum</code></a></li><li><a href="#OnlineStatsBase.Variance"><code>OnlineStatsBase.Variance</code></a></li><li><a href="#Base.merge!-Tuple{OnlineStat,OnlineStat}"><code>Base.merge!</code></a></li><li><a href="#Base.sort!-Tuple{CCIPCA}"><code>Base.sort!</code></a></li><li><a href="#OnlineStats.eigenvalue-Tuple{CCIPCA,Int64}"><code>OnlineStats.eigenvalue</code></a></li><li><a href="#OnlineStats.eigenvector-Tuple{CCIPCA,Int64}"><code>OnlineStats.eigenvector</code></a></li><li><a href="#OnlineStats.fittransform!-Tuple{CCIPCA,Array{Float64,1}}"><code>OnlineStats.fittransform!</code></a></li><li><a href="#OnlineStats.principalvar-Tuple{CCIPCA,Int64}"><code>OnlineStats.principalvar</code></a></li><li><a href="#OnlineStats.reconstruct-Tuple{CCIPCA,AbstractArray{Float64,N} where N}"><code>OnlineStats.reconstruct</code></a></li><li><a href="#OnlineStats.relativevariances-Tuple{CCIPCA}"><code>OnlineStats.relativevariances</code></a></li><li><a href="#OnlineStatsBase.smooth-Tuple{Any,Any,Any}"><code>OnlineStatsBase.smooth</code></a></li><li><a href="#OnlineStatsBase.smooth!-Tuple{Any,Any,Any}"><code>OnlineStatsBase.smooth!</code></a></li><li><a href="#OnlineStatsBase.smooth_syr!-Tuple{AbstractArray{T,2} where T,Any,Any}"><code>OnlineStatsBase.smooth_syr!</code></a></li><li><a href="#OnlineStatsBase.value-Tuple{OnlineStat}"><code>OnlineStatsBase.value</code></a></li><li><a href="#StatsBase.confint"><code>StatsBase.confint</code></a></li><li><a href="#StatsBase.fit!-Union{Tuple{T}, Tuple{OnlineStat{T},T}} where T"><code>StatsBase.fit!</code></a></li><li><a href="#StatsBase.transform-Tuple{CCIPCA,AbstractArray{Float64,N} where N}"><code>StatsBase.transform</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ADADELTA" href="#OnlineStats.ADADELTA"><code>OnlineStats.ADADELTA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ADADELTA(ρ = .95)</code></pre><p>An extension of <a href="#OnlineStats.ADAGRAD"><code>ADAGRAD</code></a>.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L88-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ADAGRAD" href="#OnlineStats.ADAGRAD"><code>OnlineStats.ADAGRAD</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ADAGRAD()</code></pre><p>A variation of <a href="#OnlineStats.SGD"><code>SGD</code></a> with element-wise weights generated by the average of the squared gradients.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li><li>Note: ADAGRAD uses a learning rate in OnlineStats, which differs from how it is typically presented. See https://www.seqstat.com/post/adagrad/ for details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L39-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ADAM" href="#OnlineStats.ADAM"><code>OnlineStats.ADAM</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ADAM(β1 = .99, β2 = .999)</code></pre><p>A variant of <a href="#OnlineStats.SGD"><code>SGD</code></a> with element-wise learning rates generated by exponentially weighted first and second moments of the gradient.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L119-L126">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ADAMAX" href="#OnlineStats.ADAMAX"><code>OnlineStats.ADAMAX</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ADAMAX(η, β1 = .9, β2 = .999)</code></pre><p>ADAMAX with momentum parameters <code>β1</code>, <code>β2</code>.  ADAMAX is an extension of <a href="#OnlineStats.ADAM"><code>ADAM</code></a>.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L151-L157">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Ash" href="#OnlineStats.Ash"><code>OnlineStats.Ash</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Ash(h::Union{KHist, Hist, ExpandingHist})
Ash(h::Union{KHist, Hist, ExpandingHist}, m::Int, kernel::Function)</code></pre><p>Create an Average Shifted Histogram using <code>h</code> as the base histogram with smoothing parameter <code>m</code>  and kernel function <code>kernel</code>.  Built-in kernels are available in the <code>OnlineStats.Kernels</code> module.</p><p><strong>Example</strong></p><pre><code class="language-none">using OnlineStats, Plots

o = fit!(Ash(ExpandingHist(1000)), randn(10^6))

plot(o)
plot(o, 20)
plot(o, OnlineStats.Kernels.epanechnikov, 4)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/ash.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.AutoCov" href="#OnlineStats.AutoCov"><code>OnlineStats.AutoCov</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AutoCov(b, T = Float64; weight=EqualWeight())</code></pre><p>Calculate the auto-covariance/correlation for lags 0 to <code>b</code> for a data stream of type <code>T</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">y = cumsum(randn(100))
o = AutoCov(5)
fit!(o, y)
autocov(o)
autocor(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L36-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.BiasVec" href="#OnlineStats.BiasVec"><code>OnlineStats.BiasVec</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">BiasVec(x)</code></pre><p>Lightweight wrapper of a vector which adds a bias/intercept term at the end.</p><p><strong>Example</strong></p><pre><code class="language-none">BiasVec(rand(5))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/OnlineStats.jl#L66-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Bootstrap" href="#OnlineStats.Bootstrap"><code>OnlineStats.Bootstrap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Bootstrap(o::OnlineStat, nreps = 100, d = [0, 2])</code></pre><p>Calculate an online statistical bootstrap of <code>nreps</code> replicates of <code>o</code>.  For each call to <code>fit!</code>, any given replicate will be updated <code>rand(d)</code> times (default is double or nothing).</p><p><strong>Example</strong></p><pre><code class="language-none">o = Bootstrap(Variance())
fit!(o, randn(1000))
confint(o, .95)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L94-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.CCIPCA" href="#OnlineStats.CCIPCA"><code>OnlineStats.CCIPCA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CCIPCA(outdim::Int, indim; l::Int)</code></pre><p>Online PCA with the CCIPCA (Candid Covariance-free Incremental PCA) algorithm, where indim is the length of incoming vectors, outdim is the number of  dimension to project to, and l is the level of amnesia. Give values of l in  the range 2-4 if you want old vectors to be gradually less important, i.e.  latest vectors added get more weight.</p><p>If no indim is specified it will be set later, on first call to fit. After that it is fixed and cannot change.</p><p>The CCIPCA is a very fast, simple, and online approximation of PCA. It can be used for Dimensionality Reduction to project high-dimensional vectors into a  low-dimensional (typically 2D or 3D) space. This algorithm has shown very  good properties in comparative studies; it is both fast and give a good  approximation to (batch) PCA.</p><p><strong>Example</strong></p><pre><code class="language-none">o = CCIPCA(2, 10)                # Project 10-dimensional vectors into 2D
u1 = rand(10)
fit!(o, u1)                      # Fit to u1
u2 = rand(10)
fit!(o, u2)                      # Fit to u2
u3 = rand(10)
OnlineStats.transform(o, u3)     # Project u3 into PCA space fitted to u1 and u2 but don&#39;t change the projection
u4 = rand(10)
OnlineStats.fittransform!(o, u4) # Fit u4 and then project u4 into the space
sort!(o)                         # Sort from high to low eigenvalues
o[1]                             # Get primary (1st) eigenvector
OnlineStats.variation(o)         # Get the variation (explained) &quot;by&quot; each eigenvector</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L11-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.CallFun" href="#OnlineStats.CallFun"><code>OnlineStats.CallFun</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CallFun(o::OnlineStat, f::Function)</code></pre><p>Call <code>f(o)</code> every time the OnlineStat <code>o</code> gets updated.</p><p><strong>Example</strong></p><pre><code class="language-none">o = CallFun(Mean(), println)
fit!(o, [0,0,1,1])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L139-L148">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Cluster" href="#OnlineStats.Cluster"><code>OnlineStats.Cluster</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Cluster center and the number of observations</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L371">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Diff" href="#OnlineStats.Diff"><code>OnlineStats.Diff</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Diff(T::Type = Float64)</code></pre><p>Track the difference and the last value.</p><p><strong>Example</strong></p><pre><code class="language-none">o = Diff()
fit!(o, [1.0, 2.0])
last(o)
diff(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L161-L172">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ExpandingHist" href="#OnlineStats.ExpandingHist"><code>OnlineStats.ExpandingHist</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExpandingHist(nbins)</code></pre><p>An adaptive histogram where the bin edges keep doubling in size in order to contain every observation. <code>nbins</code> must be an even number.  Bins are left-closed and the rightmost bin is closed, e.g.</p><ul><li><code>[a, b)</code>, <code>[b, c)</code>, <code>[c, d]</code></li></ul><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(ExpandingHist(200), randn(10^6))

using Plots
plot(o)</code></pre><p><strong>Details</strong></p><p>How <code>ExpandingHist</code> works is best understood through example.  Suppose we start with a histogram  of edges/counts as follows:</p><pre><code class="language-none">|1|2|5|3|2|</code></pre><ul><li>Now we observe a data point that is not contained in the bin edges:</li></ul><pre><code class="language-none">|1|2|5|3|2|       *</code></pre><ul><li>In order to contain the point, the range of the edges doubles in the direction of the new  data point and adjacent bins merge their counts:</li></ul><pre><code class="language-none">|1|2|5|3|2|       *
 \ / \ / \ /      ↓
  ↓   ↓   ↓       ↓ 
| 3 | 8 | 2 | 0 | 1 | </code></pre><ul><li>Note that multiple iterations of bin-doubling may occur until the new point is contained by the  bin edges. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/histograms.jl#L138-L179">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FastForest" href="#OnlineStats.FastForest"><code>OnlineStats.FastForest</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FastForest(p, nkeys=2; stat=FitNormal(), kw...)</code></pre><p>Calculate a random forest where each variable is summarized by <code>stat</code>.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>nt=100)</code>: Number of trees in the forest</li><li><code>b=floor(Int, sqrt(p))</code>: Number of random features for each tree to receive</li><li><code>maxsize=1000</code>: Maximum size for any tree in the forest</li><li><code>splitsize=5000</code>: Number of observations in any given node before splitting</li><li><code>λ = .05</code>: Probability that each tree is updated on a new observation</li></ul><p><strong>Example</strong></p><pre><code class="language-none">x, y = randn(10^5, 10), rand(1:2, 10^5)

o = fit!(FastForest(10), zip(eachrow(x),y))

classify(o, x[1,:])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/fasttree.jl#L169-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FastTree" href="#OnlineStats.FastTree"><code>OnlineStats.FastTree</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FastTree(p::Int, nclasses=2; stat=FitNormal(), maxsize=5000, splitsize=1000)</code></pre><p>Calculate a decision tree of <code>p</code> predictors variables and classes <code>1, 2, …, nclasses</code>. Nodes split when they reach <code>splitsize</code> observations until <code>maxsize</code> nodes are in the tree. Each variable is summarized by <code>stat</code>, which can be <code>FitNormal()</code> or <code>Hist(nbins)</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">x = randn(10^5, 10)
y = rand([1,2], 10^5)

o = fit!(FastTree(10), zip(eachrow(x),y))

xi = randn(10)
classify(o, xi)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/fasttree.jl#L107-L123">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitBeta" href="#OnlineStats.FitBeta"><code>OnlineStats.FitBeta</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitBeta(; weight)</code></pre><p>Online parameter estimate of a Beta distribution (Method of Moments).</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(FitBeta(), rand(1000))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L2-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitCauchy" href="#OnlineStats.FitCauchy"><code>OnlineStats.FitCauchy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitCauchy(b=500)</code></pre><p>Approximate parameter estimation of a Cauchy distribution.  Estimates are based on approximated quantiles.  See <a href="#OnlineStats.Quantile"><code>Quantile</code></a> and <a href="#OnlineStats.ExpandingHist"><code>ExpandingHist</code></a> for details on how the  distribution is estimated.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(FitCauchy(), randn(1000))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L30-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitGamma" href="#OnlineStats.FitGamma"><code>OnlineStats.FitGamma</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitGamma(; weight)</code></pre><p>Online parameter estimate of a Gamma distribution (Method of Moments).</p><p><strong>Example</strong></p><pre><code class="language-none">using Random
o = fit!(FitGamma(), randexp(10^5))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L57-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitLogNormal" href="#OnlineStats.FitLogNormal"><code>OnlineStats.FitLogNormal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitLogNormal()</code></pre><p>Online parameter estimate of a LogNormal distribution (MLE).</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(FitLogNormal(), exp.(randn(10^5)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L85-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitMultinomial" href="#OnlineStats.FitMultinomial"><code>OnlineStats.FitMultinomial</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitMultinomial(p)</code></pre><p>Online parameter estimate of a Multinomial distribution.  The sum of counts does not need to be consistent across observations.  Therefore, the <code>n</code> parameter of the Multinomial distribution is returned as 1.</p><p><strong>Example</strong></p><pre><code class="language-none">x = [1 2 3; 4 8 12]
fit!(FitMultinomial(3), x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L155-L165">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitMvNormal" href="#OnlineStats.FitMvNormal"><code>OnlineStats.FitMvNormal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitMvNormal(d)</code></pre><p>Online parameter estimate of a <code>d</code>-dimensional MvNormal distribution (MLE).</p><p><strong>Example</strong></p><pre><code class="language-none">y = randn(100, 2)
o = fit!(FitMvNormal(2), eachrow(y))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L182-L191">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.FitNormal" href="#OnlineStats.FitNormal"><code>OnlineStats.FitNormal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FitNormal()</code></pre><p>Calculate the parameters of a normal distribution via maximum likelihood.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(FitNormal(), randn(1000))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/distributions.jl#L109-L116">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.HeatMap" href="#OnlineStats.HeatMap"><code>OnlineStats.HeatMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Heatmap(xedges, yedges; left = true, closed = true)
Heatmap(itr; left = true, closed = true)</code></pre><p>Create a two dimensional histogram with the bin partition created by <code>xedges</code> and <code>yedges</code>. When fitting a new observation, the first value will be associated with X, the second with Y.</p><ul><li>If <code>left</code>, the bins will be left-closed.</li><li>If <code>closed</code>, the bins on the ends will be closed.  See <a href="@ref">Hist</a>.</li></ul><p><strong>Example</strong></p><pre><code class="language-none">using Plots

xy = zip(randn(10^6), randn(10^6))
o = fit!(HeatMap(-5:.1:5, -5:.1:5), xy)
plot(o)

xy = zip(1 .+ randn(10^6) ./ 10, randn(10^6))
o = HeatMap(xy)
plot(o, marginals=false)
plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/heatmap.jl#L1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Hist" href="#OnlineStats.Hist"><code>OnlineStats.Hist</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Hist(edges; left = true, closed = true)</code></pre><p>Create a histogram with bin partition defined by <code>edges</code>.</p><ul><li>If <code>left</code>, the bins will be left-closed.</li><li>If <code>closed</code>, the bin on the end will be closed.<ul><li>E.g. for a two bin histogram <span>$[a, b), [b, c)$</span> vs. <span>$[a, b), [b, c]$</span></li></ul></li></ul><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(Hist(-5:.1:5), randn(10^6))

# approximate statistics
using Statistics

mean(o)
var(o)
std(o)
quantile(o)
median(o)
extrema(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/histograms.jl#L46-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.HyperLogLog" href="#OnlineStats.HyperLogLog"><code>OnlineStats.HyperLogLog</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">HyperLogLog(T = Number)
HyperLogLog{P}(T = Number)</code></pre><p>Approximate count of distinct elements of a data stream of type <code>T</code>, using <code>2 ^ P</code> &quot;registers&quot;.  <code>P</code> must be an integer between 4 and 16 (default).</p><p>By default it returns the improved HyperLogLog cardinality estimator as defined by <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>.</p><p>The original HyperLogLog estimator <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> can be retrieved with the option <code>original_estimator=true</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">o = HyperLogLog()
fit!(o, rand(1:100, 10^6))

using Random
o2 = HyperLogLog(String)
fit!(o2, [randstring(20) for i in 1:1000])

# by default the improved estimator is returned:
value(o)
# the original HyperLogLog estimator can be retrieved via:
value(o; original_estimator=true)</code></pre><p><strong>References</strong></p><p><sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> Improved estimator: Otmar Ertl. New cardinality estimation algorithms for HyperLogLog sketches. <a href="https://arxiv.org/abs/1702.01284">https://arxiv.org/abs/1702.01284</a></p><p><sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> Original estimator: P. Flajolet, Éric Fusy, O. Gandouet, and F. Meunier. Hyperloglog: The analysis of a near-optimal cardinality estimation algorithm. <em>In Analysis of Algorithms (AOFA)</em>, pages 127–146, 2007.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L228-L264">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.IndexedPartition" href="#OnlineStats.IndexedPartition"><code>OnlineStats.IndexedPartition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">IndexedPartition(T, stat, b=100)</code></pre><p>Summarize data with <code>stat</code> over a partition of size <code>b</code> where the data is indexed by a  variable of type <code>T</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y = randn(10^5), randn(10^6)
o = IndexedPartition(Float64, KHist(10))
fit!(o, zip(x, y))

using Plots 
plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/partition.jl#L69-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KHist" href="#OnlineStats.KHist"><code>OnlineStats.KHist</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KHist(k::Int)</code></pre><p>Estimate the probability density of a univariate distribution at <code>k</code> approximately equally-spaced points.  </p><p>Ref: <a href="https://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf">https://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf</a></p><p>A difference from the above reference is that the minimum and maximum values are not allowed to merge into another bin.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(KHist(25), randn(10^6))

# Approximate statistics
using Statistics
mean(o)
var(o)
std(o)
quantile(o)
median(o)

using Plots
plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/khist.jl#L1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KHist2D" href="#OnlineStats.KHist2D"><code>OnlineStats.KHist2D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KHist2D(b=300)</code></pre><p>Approximate scatterplot of <code>b</code> centers.  This implementation is slow!  See <a href="#OnlineStats.IndexedPartition"><code>IndexedPartition</code></a> and <a href="#OnlineStats.KIndexedPartition"><code>KIndexedPartition</code></a> instead.</p><p><strong>Example</strong></p><pre><code class="language-none">x = randn(10^4)
y = x + randn(10^4)
plot(fit!(KHist2D(), zip(x, y)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/khist2d.jl#L16-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KIndexedPartition" href="#OnlineStats.KIndexedPartition"><code>OnlineStats.KIndexedPartition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KIndexedPartition(T, stat_init, k=100)</code></pre><p>Similar to <a href="#OnlineStats.IndexedPartition"><code>IndexedPartition</code></a>, but indexes the first variable by centroids (like <a href="#OnlineStats.KHist"><code>KHist</code></a>) rather than intervals.  </p><ul><li>Note: <code>stat_init</code> must be a function e.g. <code>() -&gt; Mean()</code></li></ul><p><strong>Example</strong></p><pre><code class="language-none">using Plots 

o = KIndexedPartition(Float64, () -&gt; KHist(10))

fit!(o, zip(randn(10^6), randn(10^6)))

plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/partition.jl#L153-L169">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KMeans" href="#OnlineStats.KMeans"><code>OnlineStats.KMeans</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KMeans(k; rate=LearningRate(.6))</code></pre><p>Approximate K-Means clustering of <code>k</code> clusters.</p><p><strong>Example</strong></p><pre><code class="language-none">x = [randn() + 5i for i in rand(Bool, 10^6), j in 1:2]

o = fit!(KMeans(2, 2), eachrow(x)) 

sort!(o; rev=true)  # Order clusters by number of observations</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L382-L394">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KahanMean" href="#OnlineStats.KahanMean"><code>OnlineStats.KahanMean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KahanMean(; T=Float64, weight=EqualWeight())</code></pre><p>Track a univariate mean. Uses a compensation term for the update.</p><p>#Note</p><p>This should be more accurate as <a href="#OnlineStatsBase.Mean"><code>Mean</code></a> in most cases but the guarantees of <a href="#OnlineStats.KahanSum"><code>KahanSum</code></a> do not apply. <a href="#Base.merge!-Tuple{OnlineStat,OnlineStat}"><code>merge!</code></a> can have some accuracy issues.</p><p><strong>Update</strong></p><p><span>$μ = (1 - γ) * μ + γ * x$</span></p><p><strong>Example</strong></p><pre><code class="language-none">@time fit!(KahanMean(), randn(10^6))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/kahan.jl#L52-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KahanSum" href="#OnlineStats.KahanSum"><code>OnlineStats.KahanSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KahanSum(T::Type = Float64)</code></pre><p>Track the overall sum. Includes a compensation term that effectively doubles precision, see <a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm">Wikipedia</a> for details.</p><p><strong>Example</strong></p><pre><code class="language-none">fit!(KahanSum(Float64), fill(1, 100))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/kahan.jl#L3-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.KahanVariance" href="#OnlineStats.KahanVariance"><code>OnlineStats.KahanVariance</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KahanVariance(; T=Float64, weight=EqualWeight())</code></pre><p>Track the univariate variance. Uses compensation terms for a higher accuracy.</p><p>#Note</p><p>This should be more accurate as <a href="#OnlineStatsBase.Variance"><code>Variance</code></a> in most cases but the guarantees of <a href="#OnlineStats.KahanSum"><code>KahanSum</code></a> do not apply. <a href="#Base.merge!-Tuple{OnlineStat,OnlineStat}"><code>merge!</code></a> can have accuracy issues.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(KahanVariance(), randn(10^6))
mean(o)
var(o)
std(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/kahan.jl#L112-L129">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Lag" href="#OnlineStats.Lag"><code>OnlineStats.Lag</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Lag(T, b::Int)</code></pre><p>Store the last <code>b</code> values for a data stream of type <code>T</code>.  Values are stored as</p><p><span>$v(t), v(t-1), v(t-2), …, v(t-b+1)$</span></p><p>so that <code>value(o::Lag)[1]</code> is the most recent observation and <code>value(o::Lag)[end]</code> is the <code>b</code>-th most recent observation.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(Lag(Int, 10), 1:12)
o[1]
o[end]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L3-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.LinReg" href="#OnlineStats.LinReg"><code>OnlineStats.LinReg</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinReg()</code></pre><p>Linear regression, optionally with element-wise ridge regularization.</p><p><strong>Example</strong></p><pre><code class="language-none">x = randn(100, 5)
y = x * (1:5) + randn(100)
o = fit!(LinReg(), zip(eachrow(x),y))
coef(o)
coef(o, .1)
coef(o, [0,0,0,0,Inf])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/linreg.jl#L2-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.LinRegBuilder" href="#OnlineStats.LinRegBuilder"><code>OnlineStats.LinRegBuilder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinRegBuilder(p)</code></pre><p>Create an object from which any variable can be regressed on any other set of variables, optionally with element-wise ridge regularization.  The main function to use with <code>LinRegBuilder</code> is <code>coef</code>:</p><pre><code class="language-none">coef(o::LinRegBuilder, λ = 0; y=1, x=[2,3,...], bias=true, verbose=false)</code></pre><p>Return the coefficients of a regressing column <code>y</code> on columns <code>x</code> with ridge (<code>abs2</code> penalty) parameter <code>λ</code>.  An intercept (<code>bias</code>) term is added by default.</p><p><strong>Examples</strong></p><pre><code class="language-none">x = randn(1000, 10)
o = fit!(LinRegBuilder(), eachrow(x))

coef(o; y=3, verbose=true)

coef(o; y=7, x=[2,5,4])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/linreg.jl#L61-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.MSPI" href="#OnlineStats.MSPI"><code>OnlineStats.MSPI</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MSPI()</code></pre><p>Majorized Stochastic Proximal Iteration.</p><ul><li>Reference: https://repository.lib.ncsu.edu/handle/1840.20/34945</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L212-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Mosaic" href="#OnlineStats.Mosaic"><code>OnlineStats.Mosaic</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Mosaic(T::Type, S::Type)</code></pre><p>Data structure for generating a mosaic plot, a comparison between two categorical variables.</p><p><strong>Example</strong></p><pre><code class="language-none">using OnlineStats, Plots 
x = [rand() &gt; .8 for i in 1:10^5]
y = rand([1,2,2,3,3,3], 10^5)
o = fit!(Mosaic(Bool, Int), zip(x, y))
plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/mosaicplot.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.MovingTimeWindow" href="#OnlineStats.MovingTimeWindow"><code>OnlineStats.MovingTimeWindow</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MovingTimeWindow{T&lt;:TimeType, S}(window::Dates.Period)
MovingTimeWindow(window::Dates.Period; valtype=Float64, timetype=Date)</code></pre><p>Fit a moving window of data based on time stamps.  Each observation must be a <code>Tuple</code>, <code>NamedTuple</code>, or <code>Pair</code> where the first item is <code>&lt;: Dates.TimeType</code>.  Observations with a <code>timestamp</code> NOT in the range</p><pre><code class="language-none">now() - window ≤ timestamp ≤ now()</code></pre><p>are discarded on every <code>fit!</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">using Dates
dts = Date(2010):Day(1):Date(2011)
y = rand(length(dts))

o = MovingTimeWindow(Day(4); timetype=Date, valtype=Float64)
fit!(o, zip(dts, y))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L436-L458">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.MovingWindow" href="#OnlineStats.MovingWindow"><code>OnlineStats.MovingWindow</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MovingWindow(b, T)
MovingWindow(T, b)</code></pre><p>Track a moving window of <code>b</code> items of type <code>T</code>.  Also known as a circular buffer.</p><p><strong>Example</strong></p><pre><code class="language-none">o = MovingWindow(10, Int)
fit!(o, 1:14)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L487-L497">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.NBClassifier" href="#OnlineStats.NBClassifier"><code>OnlineStats.NBClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NBClassifier(p::Int, T::Type; stat = Hist(15))</code></pre><p>Calculate a naive bayes classifier for classes of type <code>T</code> and <code>p</code> predictors.  For each class <code>K</code>, predictor variables are summarized by the <code>stat</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y = randn(10^4, 10), rand(Bool, 10^4)

o = fit!(NBClassifier(10, Bool), zip(eachrow(x),y))
collect(keys(o))
probs(o)

xi = randn(10)
predict(o, xi)
classify(o, xi)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/nbclassifier.jl#L46-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.OMAP" href="#OnlineStats.OMAP"><code>OnlineStats.OMAP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">OMAP()</code></pre><p>Online MM via Averaged Parameter.</p><ul><li>Reference: https://repository.lib.ncsu.edu/handle/1840.20/34945</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L221-L227">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.OMAS" href="#OnlineStats.OMAS"><code>OnlineStats.OMAS</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">OMAS()</code></pre><p>Online MM via Averaged Surrogate.</p><ul><li>Reference: https://repository.lib.ncsu.edu/handle/1840.20/34945</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L230-L236">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.OrderStats" href="#OnlineStats.OrderStats"><code>OnlineStats.OrderStats</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">OrderStats(b::Int, T::Type = Float64; weight=EqualWeight())</code></pre><p>Average order statistics with batches of size <code>b</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(OrderStats(100), randn(10^5))
quantile(o, [.25, .5, .75])

f = ecdf(o)
f(0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L528-L540">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.P2Quantile" href="#OnlineStats.P2Quantile"><code>OnlineStats.P2Quantile</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">P2Quantile(τ = 0.5)</code></pre><p>Calculate the approximate quantile via the P^2 algorithm.  It is more computationally expensive than the algorithms used by <a href="#OnlineStats.Quantile"><code>Quantile</code></a>, but also more exact.</p><p>Ref: <a href="https://www.cse.wustl.edu/~jain/papers/ftp/psqr.pdf">https://www.cse.wustl.edu/~jain/papers/ftp/psqr.pdf</a></p><p><strong>Example</strong></p><pre><code class="language-none">fit!(P2Quantile(.5), rand(10^5))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L642-L653">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Partition" href="#OnlineStats.Partition"><code>OnlineStats.Partition</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Partition(stat, nparts=100)</code></pre><p>Split a data stream into <code>nparts</code> where each part is summarized by <code>stat</code>.  </p><p><strong>Example</strong></p><pre><code class="language-none">o = Partition(Extrema())
fit!(o, cumsum(randn(10^5)))

using Plots
plot(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/viz/partition.jl#L12-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ProbMap" href="#OnlineStats.ProbMap"><code>OnlineStats.ProbMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ProbMap(T::Type; weight=EqualWeight())
ProbMap(A::AbstractDict{T, Float64}; weight=EqualWeight())</code></pre><p>Track a dictionary that maps unique values to its probability.  Similar to <a href="#OnlineStatsBase.CountMap"><code>CountMap</code></a>, but uses a weighting mechanism.</p><p><strong>Example</strong></p><pre><code class="language-none">o = ProbMap(Int)
fit!(o, rand(1:10, 1000))
probs(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L593-L605">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.Quantile" href="#OnlineStats.Quantile"><code>OnlineStats.Quantile</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Quantile(q::Vector{Float64} = [0, .25, .5, .75, 1]; b=500)</code></pre><p>Calculate (approximate) quantiles from a data stream.  Internally uses <a href="#OnlineStats.ExpandingHist"><code>ExpandingHist</code></a> to  estimate the distribution, for which <code>b</code> is the number of histogram bins.  Setting <code>b</code> to a larger number will decrease speed, but increase accuracy.</p><p><strong>Example</strong></p><pre><code class="language-none">q = [.25, .5, .75]
x = randn(10^6)

o = fit!(Quantile(q, b=1000), randn(10^6))
value(o)

quantile(x, q)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L733-L749">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.RMSPROP" href="#OnlineStats.RMSPROP"><code>OnlineStats.RMSPROP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RMSPROP(α = .9)</code></pre><p>A Variation of <a href="#OnlineStats.ADAGRAD"><code>ADAGRAD</code></a> that uses element-wise weights generated by an exponentially  weighted mean of the squared gradients.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L63-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.ReservoirSample" href="#OnlineStats.ReservoirSample"><code>OnlineStats.ReservoirSample</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ReservoirSample(k::Int, T::Type = Float64)</code></pre><p>Create a sample without replacement of size <code>k</code>.  After running through <code>n</code> observations, the probability of an observation being in the sample is <code>1 / n</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">fit!(ReservoirSample(100, Int), 1:1000)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L764-L773">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.SGD" href="#OnlineStats.SGD"><code>OnlineStats.SGD</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SGD()</code></pre><p>Stochastic Gradient Descent.</p><ul><li>Reference: https://ruder.io/optimizing-gradient-descent/</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/algorithms.jl#L10-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.StatLag" href="#OnlineStats.StatLag"><code>OnlineStats.StatLag</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StatLag(stat, b)</code></pre><p>Track a moving window (previous <code>b</code> copies) of <code>stat</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">fit!(StatLag(Mean(), 10), 1:20)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L195-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.StatLearn" href="#OnlineStats.StatLearn"><code>OnlineStats.StatLearn</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StatLearn(args...; penalty=zero, rate=LearningRate())</code></pre><p>Fit a model (via stochastic approximation) that is linear in the parameters.  The (offline)  objective function that StatLearn approximately minimizes is</p><p><span>$(1/n) ∑ᵢ f(yᵢ, xᵢ&#39;β) + ∑ⱼ λⱼ g(βⱼ),$</span></p><p>where <span>$fᵢ$</span> are loss functions of a response variable and linear predictor, <span>$λⱼ$</span>s are nonnegative regularization parameters, and <span>$g$</span> is a penalty function.</p><p>Use <code>StatLearn</code> with caution, as stochastic approximation algorithms are inherently noisy.</p><p><strong>Arguments</strong></p><ul><li><code>loss = OnlineStats.l2regloss</code>: The loss function to be (approximately) minimized.<ul><li>Regression Losses:<ul><li><code>l2regloss</code>: Squared error loss</li><li><code>l1regloss</code>: Absolute error loss</li></ul></li><li>Classification (y ∈ {-1, 1}) Losses:<ul><li><code>logisticloss</code>: Logistic regression</li><li><code>l1hingeloss</code>: Loss function used in Support Vector Machines.</li><li><code>DWDLoss(q)</code>: Generalized Distance Weighted Discrimination (smoothed <code>l1hingeloss</code>)</li></ul></li></ul></li><li><code>algorithm = SGD()</code>: The stochastic approximation method to be used.<ul><li>Algorithms based on Stochastic gradient:<ul><li><code>SGD()</code>: Stochastic Gradient Descent</li><li><code>ADAGRAD()</code>: AdaGrad (adaptive version of SGD)</li><li><code>RMSPROP()</code>: RMSProp (adaptive version of SGD)</li></ul></li><li>Algorithms based on Majorization-Minimization Principle:<ul><li><code>MSPI()</code>: Majorized Stochastic Proximal Iteration</li><li><code>OMAS()</code>: Online MM via Averaged Surrogate</li><li><code>OMAP()</code>: Online MM via Averaged Parameter</li></ul></li></ul></li><li><code>λ = 0.0</code>: The hyperparameter(s) used for the penalty function<ul><li>User can provide elementwise penalty hyperparameters (<code>Vector{Float64}</code>) or single hyperparameter (<code>Float64</code>).</li></ul></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>penalty</code>: The regularization function used.<ul><li><code>zero</code>: no penalty (default)</li><li><code>abs</code>: (LASSO) parameters penalized by their absolute value</li><li><code>abs2</code>: (Ridge) parameters penalized by their squared value</li><li><code>ElasticNet(α)</code>: α * (abs penalty) + (1-α) * (abs2 penalty)</li></ul></li><li><code>rate = LearningRate(.6)</code></li></ul><p><strong>Example</strong></p><pre><code class="language-none">x = randn(1000, 5)
y = x * range(-1, stop=1, length=5) + randn(1000)

o = fit!(StatLearn(MSPI()), zip(eachrow(x), y))
coef(o)

o = fit!(StatLearn(OnlineStats.l1regloss, ADAGRAD()), zip(eachrow(x), y))
coef(o)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/statlearn.jl#L51-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sort!-Tuple{CCIPCA}" href="#Base.sort!-Tuple{CCIPCA}"><code>Base.sort!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sort!(o::CCIPCA)</code></pre><p>Sort eigenvalues and their eigenvectors of <code>o</code> so highest ones come first. Useful before visualising since it ensures most variation is on the first (X) axis.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L188-L194">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.eigenvalue-Tuple{CCIPCA,Int64}" href="#OnlineStats.eigenvalue-Tuple{CCIPCA,Int64}"><code>OnlineStats.eigenvalue</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">eigenvalue(o::CCIPCA, i::Int)</code></pre><p>Get the <code>i</code>th eigenvalue of <code>o</code>. Also called principal variance for PCA.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L145-L150">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.eigenvector-Tuple{CCIPCA,Int64}" href="#OnlineStats.eigenvector-Tuple{CCIPCA,Int64}"><code>OnlineStats.eigenvector</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">eigenvector(o::CCIPCA, i::Int)</code></pre><p>Get the <code>i</code>th eigenvector of <code>o</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L162-L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.fittransform!-Tuple{CCIPCA,Array{Float64,1}}" href="#OnlineStats.fittransform!-Tuple{CCIPCA,Array{Float64,1}}"><code>OnlineStats.fittransform!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fittransform!(o::CCIPCA, u::Vector{Float64})</code></pre><p>First <code>fit!</code> and then <code>transform</code> the vector <code>u</code> into the PCA space represented by <code>o</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L135-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.principalvar-Tuple{CCIPCA,Int64}" href="#OnlineStats.principalvar-Tuple{CCIPCA,Int64}"><code>OnlineStats.principalvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">eigenvalue(o::CCIPCA, i::Int)</code></pre><p>Get the <code>i</code>th eigenvalue of <code>o</code>. Also called principal variance for PCA.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L155-L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.reconstruct-Tuple{CCIPCA,AbstractArray{Float64,N} where N}" href="#OnlineStats.reconstruct-Tuple{CCIPCA,AbstractArray{Float64,N} where N}"><code>OnlineStats.reconstruct</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reconstruct(o::CCIPCA, uproj::AbstractArray{Float64})</code></pre><p>Reconstruct the (projected) vector <code>uproj</code> back to the original space from which <code>o</code> has been fitted.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L125-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStats.relativevariances-Tuple{CCIPCA}" href="#OnlineStats.relativevariances-Tuple{CCIPCA}"><code>OnlineStats.relativevariances</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">relativevariances(o::CCIPCA)</code></pre><p>Get the relative variance (explained) in the direction of each  eigenvector. Returns a vector of zeros if no vectors have yet been fitted. Note that this does not inclue the residual variance that is not captured in the eigenvectors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L173-L180">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.confint" href="#StatsBase.confint"><code>StatsBase.confint</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">confint(b::Bootstrap, coverageprob = .95)</code></pre><p>Return a confidence interval for a Bootstrap <code>b</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/stats.jl#L115-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.transform-Tuple{CCIPCA,AbstractArray{Float64,N} where N}" href="#StatsBase.transform-Tuple{CCIPCA,AbstractArray{Float64,N} where N}"><code>StatsBase.transform</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">transform(o::CCIPCA, u::AbstractArray{Float64})</code></pre><p>Transform (i.e. project) the vector <code>u</code> into the PCA space  represented by <code>o</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/OnlineStats.jl/blob/114e10eeef5bf3fc7f600063c8c4166ca3e2944e/src/stats/pca.jl#L113-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.CountMap" href="#OnlineStatsBase.CountMap"><code>OnlineStatsBase.CountMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CountMap(T::Type)
CountMap(dict::AbstractDict{T, Int})</code></pre><p>Track a dictionary that maps unique values to its number of occurrences.  Similar to <code>StatsBase.countmap</code>.</p><p>Counts can be incremented by values other than one (and decremented) using the <code>fit!(::CountMap{T}, ::Pair{T,Int})</code> method, e.g.</p><pre><code class="language-julia">o = fit!(CountMap(String), [&quot;A&quot;, &quot;B&quot;])
fit!(o, &quot;A&quot; =&gt; 5)  
fit!(o, &quot;A&quot; =&gt; -1)</code></pre><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(CountMap(Int), rand(1:10, 1000))
value(o)
OnlineStatsBase.probs(o)
OnlineStats.pdf(o, 1)
collect(keys(o))
sort!(o)
delete!(o, 1)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.CountMissing" href="#OnlineStatsBase.CountMissing"><code>OnlineStatsBase.CountMissing</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CountMissing(stat)</code></pre><p>Calculate a <code>stat</code> along with the count of <code>missing</code> values.  </p><p><strong>Example</strong></p><pre><code class="language-none">o = CountMissing(Mean())
fit!(o, [1, missing, 3])</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Counter" href="#OnlineStatsBase.Counter"><code>OnlineStatsBase.Counter</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Counter(T=Number)</code></pre><p>Count the number of items in a data stream with elements of type <code>T</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">fit!(Counter(Int), 1:100)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.CovMatrix" href="#OnlineStatsBase.CovMatrix"><code>OnlineStatsBase.CovMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CovMatrix(p=0; weight=EqualWeight())
CovMatrix(::Type{T}, p=0; weight=EqualWeight())</code></pre><p>Calculate a covariance/correlation matrix of <code>p</code> variables.  If the number of variables is unknown, leave the default <code>p=0</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(CovMatrix(), randn(100, 4) |&gt; eachrow)
cor(o)
cov(o)
mean(o)
var(o)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.FTSeries" href="#OnlineStatsBase.FTSeries"><code>OnlineStatsBase.FTSeries</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FTSeries(stats...; filter=x-&gt;true, transform=identity)</code></pre><p>Track multiple stats for one data stream that is filtered and transformed before being fitted.</p><pre><code class="language-none">FTSeries(T, stats...; filter, transform)</code></pre><p>Create an FTSeries and specify the type <code>T</code> of the pre-transformed values.</p><p><strong>Example</strong></p><pre><code class="language-none">o = FTSeries(Mean(), Variance(); transform=abs)
fit!(o, -rand(1000))

# Remove missing values represented as DataValues
using DataValues
y = DataValueArray(randn(100), rand(Bool, 100))
o = FTSeries(DataValue, Mean(); transform=get, filter=!isna)
fit!(o, y)

# Remove missing values represented as Missing
y = [rand(Bool) ? rand() : missing for i in 1:100]
o = FTSeries(Mean(); filter=!ismissing)
fit!(o, y)

# Alternatively for Missing:
fit!(Mean(), skipmissing(y))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Group" href="#OnlineStatsBase.Group"><code>OnlineStatsBase.Group</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Group(stats::OnlineStat...)
Group(; stats...)
Group(collection)</code></pre><p>Create a vector-input stat from several scalar-input stats.  For a new observation <code>y</code>, <code>y[i]</code> is sent to <code>stats[i]</code>.</p><p><strong>Examples</strong></p><pre><code class="language-none">x = randn(100, 2)

fit!(Group(Mean(), Mean()), eachrow(x))
fit!(Group(Mean(), Variance()), eachrow(x))

o = fit!(Group(m1 = Mean(), m2 = Mean()), eachrow(x))
o.stats.m1
o.stats.m2</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.GroupBy" href="#OnlineStatsBase.GroupBy"><code>OnlineStatsBase.GroupBy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GroupBy(T, stat)</code></pre><p>Update <code>stat</code> for each group (of type <code>T</code>).  A single observation is either a (named) tuple with two elements or a Pair.</p><p><strong>Example</strong></p><pre><code class="language-none">x = rand(Bool, 10^5)
y = x .+ randn(10^5)
fit!(GroupBy(Bool, Series(Mean(), Extrema())), zip(x,y))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Mean" href="#OnlineStatsBase.Mean"><code>OnlineStatsBase.Mean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Mean(T = Float64; weight=EqualWeight())</code></pre><p>Track a univariate mean, stored as type <code>T</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">@time fit!(Mean(), randn(10^6))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Moments" href="#OnlineStatsBase.Moments"><code>OnlineStatsBase.Moments</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Moments(; weight=EqualWeight())</code></pre><p>First four non-central moments.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(Moments(), randn(1000))
mean(o)
var(o)
std(o)
skewness(o)
kurtosis(o)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Series" href="#OnlineStatsBase.Series"><code>OnlineStatsBase.Series</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Series(stats)
Series(stats...)
Series(; stats...)</code></pre><p>Track a collection stats for one data stream.</p><p><strong>Example</strong></p><pre><code class="language-none">s = Series(Mean(), Variance())
fit!(s, randn(1000))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Sum" href="#OnlineStatsBase.Sum"><code>OnlineStatsBase.Sum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Sum(T::Type = Float64)</code></pre><p>Track the overall sum.</p><p><strong>Example</strong></p><pre><code class="language-none">fit!(Sum(Int), fill(1, 100))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.Variance" href="#OnlineStatsBase.Variance"><code>OnlineStatsBase.Variance</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Variance(T = Float64; weight=EqualWeight())</code></pre><p>Univariate variance, tracked as type <code>T</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">o = fit!(Variance(), randn(10^6))
mean(o)
var(o)
std(o)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.merge!-Tuple{OnlineStat,OnlineStat}" href="#Base.merge!-Tuple{OnlineStat,OnlineStat}"><code>Base.merge!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">merge!(stat1, stat2)</code></pre><p>Merge <code>stat1</code> into <code>stat2</code> (supported by most <code>OnlineStat</code> types).</p><p><strong>Example</strong></p><pre><code class="language-none">a = fit!(Mean(), 1:10)
b = fit!(Mean(), 11:20)
merge!(a, b)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.smooth!-Tuple{Any,Any,Any}" href="#OnlineStatsBase.smooth!-Tuple{Any,Any,Any}"><code>OnlineStatsBase.smooth!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">smooth!(a, b, γ)</code></pre><p>Update <code>a</code> in place by applying the <a href="#OnlineStatsBase.smooth-Tuple{Any,Any,Any}"><code>smooth</code></a> function elementwise with <code>b</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.smooth-Tuple{Any,Any,Any}" href="#OnlineStatsBase.smooth-Tuple{Any,Any,Any}"><code>OnlineStatsBase.smooth</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">smooth(a, b, γ)</code></pre><p>Weighted average of <code>a</code> and <code>b</code> with weight <code>γ</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.smooth_syr!-Tuple{AbstractArray{T,2} where T,Any,Any}" href="#OnlineStatsBase.smooth_syr!-Tuple{AbstractArray{T,2} where T,Any,Any}"><code>OnlineStatsBase.smooth_syr!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">smooth_syr!(A::AbstractMatrix, x, γ::Number)</code></pre><p>Weighted average of symmetric rank-1 update.  Updates the upper triangle of:</p><p><code>A = (1 - γ) * A + γ * x * x&#39;</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OnlineStatsBase.value-Tuple{OnlineStat}" href="#OnlineStatsBase.value-Tuple{OnlineStat}"><code>OnlineStatsBase.value</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">value(stat::OnlineStat)</code></pre><p>Calculate the value of <code>stat</code> from its &quot;sufficient statistics&quot;.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.fit!-Union{Tuple{T}, Tuple{OnlineStat{T},T}} where T" href="#StatsBase.fit!-Union{Tuple{T}, Tuple{OnlineStat{T},T}} where T"><code>StatsBase.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fit!(stat::OnlineStat, data)</code></pre><p>Update the &quot;sufficient statistics&quot; of a <code>stat</code> with more data.   If <code>typeof(data)</code> is not the type of a single observation for the provided <code>stat</code>, <code>fit!</code> will attempt to iterate through and <code>fit!</code> each item in <code>data</code>.  Therefore, <code>fit!(Mean(), 1:10)</code> translates roughly to:</p><pre><code class="language-none">o = Mean()
for x in 1:10
    fit!(o, x)
end</code></pre></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../weights/">« Weights</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 21 March 2021 02:06">Sunday 21 March 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
