var documenterSearchIndex = {"docs":
[{"location":"api/#API-1","page":"API","title":"API","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"","category":"page"},{"location":"api/#","page":"API","title":"API","text":"Modules = [OnlineStats, OnlineStatsBase]\nFilter = T -> typeof(T) === DataType ? !(T <: OnlineStats.Weight) : true","category":"page"},{"location":"api/#OnlineStats.ADADELTA","page":"API","title":"OnlineStats.ADADELTA","text":"ADADELTA(ρ = .95)\n\nAn extension of ADAGRAD.\n\nReference: https://ruder.io/optimizing-gradient-descent/\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.ADAGRAD","page":"API","title":"OnlineStats.ADAGRAD","text":"ADAGRAD()\n\nA variation of SGD with element-wise weights generated by the average of the squared gradients.\n\nReference: https://ruder.io/optimizing-gradient-descent/\nNote: ADAGRAD uses a learning rate in OnlineStats, which differs from how it is typically presented. See https://www.seqstat.com/post/adagrad/ for details.\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.ADAM","page":"API","title":"OnlineStats.ADAM","text":"ADAM(β1 = .99, β2 = .999)\n\nA variant of SGD with element-wise learning rates generated by exponentially weighted first and second moments of the gradient.\n\nReference: https://ruder.io/optimizing-gradient-descent/\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.ADAMAX","page":"API","title":"OnlineStats.ADAMAX","text":"ADAMAX(η, β1 = .9, β2 = .999)\n\nADAMAX with momentum parameters β1, β2.  ADAMAX is an extension of ADAM.\n\nReference: https://ruder.io/optimizing-gradient-descent/\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.AutoCov","page":"API","title":"OnlineStats.AutoCov","text":"AutoCov(b, T = Float64; weight=EqualWeight())\n\nCalculate the auto-covariance/correlation for lags 0 to b for a data stream of type T.\n\nExample\n\ny = cumsum(randn(100))\no = AutoCov(5)\nfit!(o, y)\nautocov(o)\nautocor(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.BiasVec","page":"API","title":"OnlineStats.BiasVec","text":"BiasVec(x)\n\nLightweight wrapper of a vector which adds a \"bias\" term at the end.\n\nExample\n\nBiasVec(rand(5))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Bootstrap","page":"API","title":"OnlineStats.Bootstrap","text":"Bootstrap(o::OnlineStat, nreps = 100, d = [0, 2])\n\nCalculate an online statistical bootstrap of nreps replicates of o.  For each call to fit!, any given replicate will be updated rand(d) times (default is double or nothing).\n\nExample\n\no = Bootstrap(Variance())\nfit!(o, randn(1000))\nconfint(o, .95)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.CCIPCA","page":"API","title":"OnlineStats.CCIPCA","text":"CCIPCA(outdim::Int, indim; l::Int)\n\nOnline PCA with the CCIPCA (Candid Covariance-free Incremental PCA) algorithm, where indim is the length of incoming vectors, outdim is the number of  dimension to project to, and l is the level of amnesia. Give values of l in  the range 2-4 if you want old vectors to be gradually less important, i.e.  latest vectors added get more weight.\n\nIf no indim is specified it will be set later, on first call to fit. After that it is fixed and cannot change.\n\nThe CCIPCA is a very fast, simple, and online approximation of PCA. It can be used for Dimensionality Reduction to project high-dimensional vectors into a  low-dimensional (typically 2D or 3D) space. This algorithm has shown very  good properties in comparative studies; it is both fast and give a good  approximation to (batch) PCA.\n\nExample\n\no = CCIPCA(2, 10)                # Project 10-dimensional vectors into 2D\nu1 = rand(10)\nfit!(o, u1)                      # Fit to u1\nu2 = rand(10)\nfit!(o, u2)                      # Fit to u2\nu3 = rand(10)\nOnlineStats.transform(o, u3)     # Project u3 into PCA space fitted to u1 and u2 but don't change the projection\nu4 = rand(10)\nOnlineStats.fittransform!(o, u4) # Fit u4 and then project u4 into the space\nsort!(o)                         # Sort from high to low eigenvalues\no[1]                             # Get primary (1st) eigenvector\nOnlineStats.variation(o)         # Get the variation (explained) \"by\" each eigenvector\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.CallFun","page":"API","title":"OnlineStats.CallFun","text":"CallFun(o::OnlineStat, f::Function)\n\nCall f(o) every time the OnlineStat o gets updated.\n\nExample\n\no = CallFun(Mean(), println)\nfit!(o, [0,0,1,1])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Diff","page":"API","title":"OnlineStats.Diff","text":"Diff(T::Type = Float64)\n\nTrack the difference and the last value.\n\nExample\n\no = Diff()\nfit!(o, [1.0, 2.0])\nlast(o)\ndiff(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FastForest","page":"API","title":"OnlineStats.FastForest","text":"FastForest(p, nkeys=2; stat=FitNormal(), kw...)\n\nCalculate a random forest where each variable is summarized by stat.\n\nKeyword Arguments\n\nnt=100): Number of trees in the forest\nb=floor(Int, sqrt(p)): Number of random features for each tree to receive\nmaxsize=1000: Maximum size for any tree in the forest\nsplitsize=5000: Number of observations in any given node before splitting\nλ = .05: Probability that each tree is updated on a new observation\n\nExample\n\nx, y = randn(10^5, 10), rand(1:2, 10^5)\n\no = fit!(FastForest(10), zip(eachrow(x),y))\n\nclassify(o, x[1,:])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FastTree","page":"API","title":"OnlineStats.FastTree","text":"FastTree(p::Int, nclasses=2; stat=FitNormal(), maxsize=5000, splitsize=1000)\n\nCalculate a decision tree of p predictors variables and classes 1, 2, …, nclasses. Nodes split when they reach splitsize observations until maxsize nodes are in the tree. Each variable is summarized by stat, which can be FitNormal() or Hist(nbins).\n\nExample\n\nx = randn(10^5, 10)\ny = rand([1,2], 10^5)\n\no = fit!(FastTree(10), zip(eachrow(x),y))\n\nxi = randn(10)\nclassify(o, xi)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitBeta","page":"API","title":"OnlineStats.FitBeta","text":"FitBeta(; weight)\n\nOnline parameter estimate of a Beta distribution (Method of Moments).\n\nExample\n\no = fit!(FitBeta(), rand(1000))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitCauchy","page":"API","title":"OnlineStats.FitCauchy","text":"FitCauchy(; alg, rate)\n\nApproximate parameter estimation of a Cauchy distribution.  Estimates are based on quantiles, so that alg will be passed to Quantile.\n\nExample\n\no = fit!(FitCauchy(), randn(1000))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitGamma","page":"API","title":"OnlineStats.FitGamma","text":"FitGamma(; weight)\n\nOnline parameter estimate of a Gamma distribution (Method of Moments).\n\nExample\n\nusing Random\no = fit!(FitGamma(), randexp(10^5))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitLogNormal","page":"API","title":"OnlineStats.FitLogNormal","text":"FitLogNormal()\n\nOnline parameter estimate of a LogNormal distribution (MLE).\n\nExample\n\no = fit!(FitLogNormal(), exp.(randn(10^5)))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitMultinomial","page":"API","title":"OnlineStats.FitMultinomial","text":"FitMultinomial(p)\n\nOnline parameter estimate of a Multinomial distribution.  The sum of counts does not need to be consistent across observations.  Therefore, the n parameter of the Multinomial distribution is returned as 1.\n\nExample\n\nx = [1 2 3; 4 8 12]\nfit!(FitMultinomial(3), x)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitMvNormal","page":"API","title":"OnlineStats.FitMvNormal","text":"FitMvNormal(d)\n\nOnline parameter estimate of a d-dimensional MvNormal distribution (MLE).\n\nExample\n\ny = randn(100, 2)\no = fit!(FitMvNormal(2), eachrow(y))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.FitNormal","page":"API","title":"OnlineStats.FitNormal","text":"FitNormal()\n\nCalculate the parameters of a normal distribution via maximum likelihood.\n\nExample\n\no = fit!(FitNormal(), randn(1000))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.HeatMap","page":"API","title":"OnlineStats.HeatMap","text":"Heatmap(xedges, yedges; left = true, closed = true)\nHeatmap(itr; left = true, closed = true)\n\nCreate a two dimensional histogram with the bin partition created by xedges and yedges. When fitting a new observation, the first value will be associated with X, the second with Y.\n\nIf left, the bins will be left-closed.\nIf closed, the bins on the ends will be closed.  See Hist.\n\nExample\n\nusing Plots\n\nxy = zip(randn(10^6), randn(10^6))\no = fit!(HeatMap(-5:.1:5, -5:.1:5), xy)\nplot(o)\n\nxy = zip(1 .+ randn(10^6) ./ 10, randn(10^6))\no = HeatMap(xy)\nplot(o, aspect_ratio=:equal)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Hist","page":"API","title":"OnlineStats.Hist","text":"Hist(edges; left = true, closed = true)\n\nCreate a histogram with bin partition defined by edges.\n\nIf left, the bins will be left-closed.\nIf closed, the bin on the end will be closed.\nE.g. for a two bin histogram a b) b c) vs. a b) b c\n\nExample\n\no = fit!(Hist(-5:.1:5), randn(10^6))\n\n# approximate statistics\nusing Statistics\n\nmean(o)\nvar(o)\nstd(o)\nquantile(o)\nmedian(o)\nextrema(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.HyperLogLog","page":"API","title":"OnlineStats.HyperLogLog","text":"HyperLogLog(T = Number)\nHyperLogLog{P}(T = Number)\n\nApproximate count of distinct elements of a data stream of type T, using 2 ^ P \"registers\".  P must be an integer between 4 and 16 (default).\n\nRef: https://storage.googleapis.com/pub-tools-public-publication-data/pdf/40671.pdf\n\nExample\n\no = HyperLogLog()\nfit!(o, rand(1:100, 10^6))\n\nusing Random\no2 = HyperLogLog(String)\nfit!(o2, [randstring(20) for i in 1:1000])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.IndexedPartition","page":"API","title":"OnlineStats.IndexedPartition","text":"IndexedPartition(T, stat, b=100)\n\nSummarize data with stat over a partition of size b where the data is indexed by a  variable of type T.\n\nExample\n\nx, y = randn(10^5), randn(10^6)\no = IndexedPartition(Float64, KHist(10))\nfit!(o, zip(x, y))\n\nusing Plots \nplot(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.KHist","page":"API","title":"OnlineStats.KHist","text":"KHist(k::Int)\n\nEstimate the probability density of a univariate distribution at k approximately equally-spaced points.  \n\nRef: http://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf\n\nA difference from the above reference is that the minimum and maximum values are not allowed to merge into another bin.\n\nExample\n\no = fit!(KHist(25), randn(10^6))\n\n# Approximate statistics\nusing Statistics\nmean(o)\nvar(o)\nstd(o)\nquantile(o)\nmedian(o)\n\nusing Plots\nplot(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.KMeans","page":"API","title":"OnlineStats.KMeans","text":"KMeans(p, k; rate=LearningRate(.6))\n\nApproximate K-Means clustering of k clusters and p variables.\n\nExample\n\nx = [randn() + 5i for i in rand(Bool, 10^6), j in 1:2]\n\no = fit!(KMeans(2, 2), eachrow(x))\n\nsort!(o; rev=true)  # Order clusters by number of observations\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.KahanMean","page":"API","title":"OnlineStats.KahanMean","text":"KahanMean(; T=Float64, weight=EqualWeight())\n\nTrack a univariate mean. Uses a compensation term for the update.\n\n#Note\n\nThis should be more accurate as Mean in most cases but the guarantees of KahanSum do not apply. merge! can have some accuracy issues.\n\nUpdate\n\nμ = (1 - γ) * μ + γ * x\n\nExample\n\n@time fit!(KahanMean(), randn(10^6))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.KahanSum","page":"API","title":"OnlineStats.KahanSum","text":"KahanSum(T::Type = Float64)\n\nTrack the overall sum. Includes a compensation term that effectively doubles precision, see Wikipedia for details.\n\nExample\n\nfit!(KahanSum(Float64), fill(1, 100))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.KahanVariance","page":"API","title":"OnlineStats.KahanVariance","text":"KahanVariance(; T=Float64, weight=EqualWeight())\n\nTrack the univariate variance. Uses compensation terms for a higher accuracy.\n\n#Note\n\nThis should be more accurate as Variance in most cases but the guarantees of KahanSum do not apply. merge! can have accuracy issues.\n\nExample\n\no = fit!(KahanVariance(), randn(10^6))\nmean(o)\nvar(o)\nstd(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Lag","page":"API","title":"OnlineStats.Lag","text":"Lag(T, b::Int)\n\nStore the last b values for a data stream of type T.  Values are stored as\n\nv(t) v(t-1) v(t-2)  v(t-b+1)\n\nso that value(o::Lag)[1] is the most recent observation and value(o::Lag)[end] is the b-th most recent observation.\n\nExample\n\no = fit!(Lag(Int, 10), 1:12)\no[1]\no[end]\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.LinReg","page":"API","title":"OnlineStats.LinReg","text":"LinReg()\n\nLinear regression, optionally with element-wise ridge regularization.\n\nExample\n\nx = randn(100, 5)\ny = x * (1:5) + randn(100)\no = fit!(LinReg(), zip(eachrow(x),y))\ncoef(o)\ncoef(o, .1)\ncoef(o, [0,0,0,0,Inf])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.LinRegBuilder","page":"API","title":"OnlineStats.LinRegBuilder","text":"LinRegBuilder(p)\n\nCreate an object from which any variable can be regressed on any other set of variables, optionally with element-wise ridge regularization.  The main function to use with LinRegBuilder is coef:\n\ncoef(o::LinRegBuilder, λ = 0; y=1, x=[2,3,...], bias=true, verbose=false)\n\nReturn the coefficients of a regressing column y on columns x with ridge (L2Penalty) parameter λ.  An intercept (bias) term is added by default.\n\nExamples\n\nx = randn(1000, 10)\no = fit!(LinRegBuilder(), eachrow(x))\n\ncoef(o; y=3, verbose=true)\n\ncoef(o; y=7, x=[2,5,4])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.MSPI","page":"API","title":"OnlineStats.MSPI","text":"MSPI()\n\nMajorized Stochastic Proximal Iteration.\n\nReference: https://repository.lib.ncsu.edu/handle/1840.20/34945\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Mosaic","page":"API","title":"OnlineStats.Mosaic","text":"Mosaic(T::Type, S::Type)\n\nData structure for generating a mosaic plot, a comparison between two categorical variables.\n\nExample\n\nusing OnlineStats, Plots \nx = [rand() > .8 for i in 1:10^5]\ny = rand([1,2,2,3,3,3], 10^5)\no = fit!(Mosaic(Bool, Int), zip(x, y))\nplot(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.MovingTimeWindow","page":"API","title":"OnlineStats.MovingTimeWindow","text":"MovingTimeWindow{T<:TimeType, S}(window::DatePeriod)\nMovingTimeWindow(window::DatePeriod; valtype=Float64, timetype=Date)\n\nFit a moving window of data based on time stamps.  Each observation must be a Tuple, NamedTuple, or Pair where the first item is <: Dates.TimeType.  Only observations with time stamps in the range\n\nmost_recent_datetime - window = time_stamp = most_recent_datetime\n\nare kept track of.\n\nExample\n\nusing Dates\ndts = Date(2010):Day(1):Date(2011)\ny = rand(length(dts))\n\no = MovingTimeWindow(Day(4); timetype=Date, valtype=Float64)\nfit!(o, zip(dts, y))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.MovingWindow","page":"API","title":"OnlineStats.MovingWindow","text":"MovingWindow(b, T)\nMovingWindow(T, b)\n\nTrack a moving window of b items of type T.\n\nExample\n\no = MovingWindow(10, Int)\nfit!(o, 1:14)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.NBClassifier","page":"API","title":"OnlineStats.NBClassifier","text":"NBClassifier(p::Int, T::Type; stat = Hist(15))\n\nCalculate a naive bayes classifier for classes of type T and p predictors.  For each class K, predictor variables are summarized by the stat.\n\nExample\n\nx, y = randn(10^4, 10), rand(Bool, 10^4)\n\no = fit!(NBClassifier(10, Bool), zip(eachrow(x),y))\ncollect(keys(o))\nprobs(o)\n\nxi = randn(10)\npredict(o, xi)\nclassify(o, xi)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.OMAP","page":"API","title":"OnlineStats.OMAP","text":"OMAP()\n\nOnline MM via Averaged Parameter.\n\nReference: https://repository.lib.ncsu.edu/handle/1840.20/34945\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.OMAS","page":"API","title":"OnlineStats.OMAS","text":"OMAS()\n\nOnline MM via Averaged Surrogate.\n\nReference: https://repository.lib.ncsu.edu/handle/1840.20/34945\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.OrderStats","page":"API","title":"OnlineStats.OrderStats","text":"OrderStats(b::Int, T::Type = Float64; weight=EqualWeight())\n\nAverage order statistics with batches of size b.\n\nExample\n\no = fit!(OrderStats(100), randn(10^5))\nquantile(o, [.25, .5, .75])\n\nf = ecdf(o)\nf(0)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.P2Quantile","page":"API","title":"OnlineStats.P2Quantile","text":"P2Quantile(τ = 0.5)\n\nCalculate the approximate quantile via the P^2 algorithm.  It is more computationally expensive than the algorithms used by Quantile, but also more exact.\n\nRef: https://www.cse.wustl.edu/~jain/papers/ftp/psqr.pdf\n\nExample\n\nfit!(P2Quantile(.5), rand(10^5))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Partition","page":"API","title":"OnlineStats.Partition","text":"Partition(stat, nparts=100)\n\nSplit a data stream into nparts where each part is summarized by stat.  \n\nExample\n\no = Partition(Extrema())\nfit!(o, cumsum(randn(10^5)))\n\nusing Plots\nplot(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.PlotNN","page":"API","title":"OnlineStats.PlotNN","text":"PlotNN(b=300)\n\nApproximate scatterplot of b centers.  This implementation is too slow to be useful.\n\nExample\n\nx = randn(10^4)\ny = x + randn(10^4)\nplot(fit!(PlotNN(), zip(x, y)))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.ProbMap","page":"API","title":"OnlineStats.ProbMap","text":"ProbMap(T::Type; weight=EqualWeight())\nProbMap(A::AbstractDict{T, Float64}; weight=EqualWeight())\n\nTrack a dictionary that maps unique values to its probability.  Similar to CountMap, but uses a weighting mechanism.\n\nExample\n\no = ProbMap(Int)\nfit!(o, rand(1:10, 1000))\nprobs(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.Quantile","page":"API","title":"OnlineStats.Quantile","text":"Quantile(q = [.25, .5, .75]; alg=OMAS(), rate=LearningRate(.6))\n\nCalculate quantiles via a stochastic approximation algorithm OMAS, SGD, ADAGRAD, or MSPI.  For better (although slower) approximations, see P2Quantile and Hist.\n\nExample\n\nfit!(Quantile(), randn(10^5))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.RMSPROP","page":"API","title":"OnlineStats.RMSPROP","text":"RMSPROP(α = .9)\n\nA Variation of ADAGRAD that uses element-wise weights generated by an exponentially  weighted mean of the squared gradients.\n\nReference: https://ruder.io/optimizing-gradient-descent/\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.ReservoirSample","page":"API","title":"OnlineStats.ReservoirSample","text":"ReservoirSample(k::Int, T::Type = Float64)\n\nCreate a sample without replacement of size k.  After running through n observations, the probability of an observation being in the sample is 1 / n.\n\nExample\n\nfit!(ReservoirSample(100, Int), 1:1000)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.SGD","page":"API","title":"OnlineStats.SGD","text":"SGD()\n\nStochastic Gradient Descent.\n\nReference: https://ruder.io/optimizing-gradient-descent/\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.StatLag","page":"API","title":"OnlineStats.StatLag","text":"StatLag(stat, b)\n\nTrack a moving window (previous b copies) of stat.\n\nExample\n\nfit!(StatLag(Mean(), 10), 1:20)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStats.StatLearn","page":"API","title":"OnlineStats.StatLearn","text":"StatLearn(p, args...; rate=LearningRate())\n\nFit a model that is linear in the parameters.\n\nThe (offline) objective function that StatLearn approximately minimizes is\n\n(1n) ᵢ f(yᵢ xᵢβ) + ⱼ λⱼ g(βⱼ)\n\nwhere fᵢ are loss functions of a single response and linear predictor, λⱼs are nonnegative regularization parameters, and g is a penalty function.\n\nArguments\n\nloss = .5 * L2DistLoss()\npenalty = NoPenalty()\nalgorithm = SGD()\nrate = LearningRate(.6) (keyword arg)\n\nExample\n\nx = randn(1000, 5)\ny = x * range(-1, stop=1, length=5) + randn(1000)\n\no = fit!(StatLearn(5, MSPI()), zip(eachrow(x), y))\ncoef(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#StatsBase.confint","page":"API","title":"StatsBase.confint","text":"confint(b::Bootstrap, coverageprob = .95)\n\nReturn a confidence interval for a Bootstrap b.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsBase.transform-Tuple{CCIPCA,AbstractArray{Float64,N} where N}","page":"API","title":"StatsBase.transform","text":"transform(o::CCIPCA, u::AbstractArray{Float64})\n\nTransform (i.e. project) the vector u into the PCA space  represented by o.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.Cluster","page":"API","title":"OnlineStats.Cluster","text":"Cluster center and the number of observations\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.sort!-Tuple{CCIPCA}","page":"API","title":"Base.sort!","text":"sort!(o::CCIPCA)\n\nSort eigenvalues and their eigenvectors of o so highest ones come first. Useful before visualising since it ensures most variation is on the first (X) axis.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.eigenvalue-Tuple{CCIPCA,Int64}","page":"API","title":"OnlineStats.eigenvalue","text":"eigenvalue(o::CCIPCA, i::Int)\n\nGet the ith eigenvalue of o. Also called principal variance for PCA.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.eigenvector-Tuple{CCIPCA,Int64}","page":"API","title":"OnlineStats.eigenvector","text":"eigenvector(o::CCIPCA, i::Int)\n\nGet the ith eigenvector of o.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.fittransform!-Tuple{CCIPCA,Array{Float64,1}}","page":"API","title":"OnlineStats.fittransform!","text":"fittransform!(o::CCIPCA, u::Vector{Float64})\n\nFirst fit! and then transform the vector u into the PCA space represented by o.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.principalvar-Tuple{CCIPCA,Int64}","page":"API","title":"OnlineStats.principalvar","text":"eigenvalue(o::CCIPCA, i::Int)\n\nGet the ith eigenvalue of o. Also called principal variance for PCA.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.reconstruct-Tuple{CCIPCA,AbstractArray{Float64,N} where N}","page":"API","title":"OnlineStats.reconstruct","text":"reconstruct(o::CCIPCA, uproj::AbstractArray{Float64})\n\nReconstruct the (projected) vector uproj back to the original space from which o has been fitted.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStats.relativevariances-Tuple{CCIPCA}","page":"API","title":"OnlineStats.relativevariances","text":"relativevariances(o::CCIPCA)\n\nGet the relative variance (explained) in the direction of each  eigenvector. Returns a vector of zeros if no vectors have yet been fitted. Note that this does not inclue the residual variance that is not captured in the eigenvectors.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStatsBase.CountMap","page":"API","title":"OnlineStatsBase.CountMap","text":"CountMap(T::Type)\nCountMap(dict::AbstractDict{T, Int})\n\nTrack a dictionary that maps unique values to its number of occurrences.  Similar to StatsBase.countmap.\n\nExample\n\no = fit!(CountMap(Int), rand(1:10, 1000))\nvalue(o)\nprobs(o)\nOnlineStats.pdf(o, 1)\ncollect(keys(o))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.CountMissing","page":"API","title":"OnlineStatsBase.CountMissing","text":"CountMissing(stat)\n\nCalculate a stat along with the count of missing values.  \n\nExample\n\no = CountMissing(Mean())\nfit!(o, [1, missing, 3])\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Counter","page":"API","title":"OnlineStatsBase.Counter","text":"Counter(T=Number)\n\nCount the number of items in a data stream with elements of type T.\n\nExample\n\nfit!(Counter(Int), 1:100)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.CovMatrix","page":"API","title":"OnlineStatsBase.CovMatrix","text":"CovMatrix(p=0; weight=EqualWeight())\nCovMatrix(::Type{T}, p=0; weight=EqualWeight())\n\nCalculate a covariance/correlation matrix of p variables.  If the number of variables is unknown, leave the default p=0.\n\nExample\n\no = fit!(CovMatrix(), randn(100, 4) |> eachrow)\ncor(o)\ncov(o)\nmean(o)\nvar(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.FTSeries","page":"API","title":"OnlineStatsBase.FTSeries","text":"FTSeries(stats...; filter=x->true, transform=identity)\n\nTrack multiple stats for one data stream that is filtered and transformed before being fitted.\n\nFTSeries(T, stats...; filter, transform)\n\nCreate an FTSeries and specify the type T of the pre-transformed values.\n\nExample\n\no = FTSeries(Mean(), Variance(); transform=abs)\nfit!(o, -rand(1000))\n\n# Remove missing values represented as DataValues\nusing DataValues\ny = DataValueArray(randn(100), rand(Bool, 100))\no = FTSeries(DataValue, Mean(); transform=get, filter=!isna)\nfit!(o, y)\n\n# Remove missing values represented as Missing\ny = [rand(Bool) ? rand() : missing for i in 1:100]\no = FTSeries(Mean(); filter=!ismissing)\nfit!(o, y)\n\n# Alternatively for Missing:\nfit!(Mean(), skipmissing(y))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Group","page":"API","title":"OnlineStatsBase.Group","text":"Group(stats::OnlineStat...)\nGroup(; stats...)\nGroup(collection)\n\nCreate a vector-input stat from several scalar-input stats.  For a new observation y, y[i] is sent to stats[i].\n\nExamples\n\nx = randn(100, 2)\n\nfit!(Group(Mean(), Mean()), eachrow(x))\nfit!(Group(Mean(), Variance()), eachrow(x))\n\no = fit!(Group(m1 = Mean(), m2 = Mean()), eachrow(x))\no.stats.m1\no.stats.m2\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.GroupBy","page":"API","title":"OnlineStatsBase.GroupBy","text":"GroupBy(T, stat)\n\nUpdate stat for each group (of type T).  A single observation is either a (named) tuple with two elements or a Pair.\n\nExample\n\nx = rand(Bool, 10^5)\ny = x .+ randn(10^5)\nfit!(GroupBy(Bool, Series(Mean(), Extrema())), zip(x,y))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Mean","page":"API","title":"OnlineStatsBase.Mean","text":"Mean(T = Float64; weight=EqualWeight())\n\nTrack a univariate mean, stored as type T.\n\nExample\n\n@time fit!(Mean(), randn(10^6))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Moments","page":"API","title":"OnlineStatsBase.Moments","text":"Moments(; weight=EqualWeight())\n\nFirst four non-central moments.\n\nExample\n\no = fit!(Moments(), randn(1000))\nmean(o)\nvar(o)\nstd(o)\nskewness(o)\nkurtosis(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Series","page":"API","title":"OnlineStatsBase.Series","text":"Series(stats)\nSeries(stats...)\nSeries(; stats...)\n\nTrack a collection stats for one data stream.\n\nExample\n\ns = Series(Mean(), Variance())\nfit!(s, randn(1000))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Sum","page":"API","title":"OnlineStatsBase.Sum","text":"Sum(T::Type = Float64)\n\nTrack the overall sum.\n\nExample\n\nfit!(Sum(Int), fill(1, 100))\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.Variance","page":"API","title":"OnlineStatsBase.Variance","text":"Variance(T = Float64; weight=EqualWeight())\n\nUnivariate variance, tracked as type T.\n\nExample\n\no = fit!(Variance(), randn(10^6))\nmean(o)\nvar(o)\nstd(o)\n\n\n\n\n\n","category":"type"},{"location":"api/#OnlineStatsBase.value-Tuple{OnlineStat}","page":"API","title":"OnlineStatsBase.value","text":"value(stat::OnlineStat)\n\nCalculate the value of stat from its \"sufficient statistics\".\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsBase.fit!-Union{Tuple{T}, Tuple{OnlineStat{T},T}} where T","page":"API","title":"StatsBase.fit!","text":"fit!(stat::OnlineStat, data)\n\nUpdate the \"sufficient statistics\" of a stat with more data.   If typeof(data) is not the type of a single observation for the provided stat, fit! will attempt to iterate through and fit! each item in data.  Therefore, fit!(Mean(), 1:10) translates roughly to:\n\no = Mean()\nfor x in 1:10\n    fit!(o, x)\nend\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.merge!-Tuple{OnlineStat,OnlineStat}","page":"API","title":"Base.merge!","text":"merge!(stat1, stat2)\n\nMerge stat1 into stat2 (supported by most OnlineStat types).\n\nExample\n\na = fit!(Mean(), 1:10)\nb = fit!(Mean(), 11:20)\nmerge!(a, b)\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStatsBase.smooth!-Tuple{Any,Any,Any}","page":"API","title":"OnlineStatsBase.smooth!","text":"smooth!(a, b, γ)\n\nUpdate a in place by applying the smooth function elementwise with b.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStatsBase.smooth-Tuple{Any,Any,Any}","page":"API","title":"OnlineStatsBase.smooth","text":"smooth(a, b, γ)\n\nWeighted average of a and b with weight γ.\n\n\n\n\n\n","category":"method"},{"location":"api/#OnlineStatsBase.smooth_syr!-Tuple{AbstractArray{T,2} where T,Any,Any}","page":"API","title":"OnlineStatsBase.smooth_syr!","text":"smooth_syr!(A::AbstractMatrix, x, γ::Number)\n\nWeighted average of symmetric rank-1 update.  Updates the upper triangle of:\n\nA = (1 - γ) * A + γ * x * x'\n\n\n\n\n\n","category":"method"},{"location":"weights/#Weights-1","page":"Weights","title":"Weights","text":"","category":"section"},{"location":"weights/#","page":"Weights","title":"Weights","text":"Many OnlineStats are parameterized by a Weight that controls the influence of new observations.  If the OnlineStat is capable of calculating the same result as a corresponding offline estimator, it will have a keyword argument weight.  If the OnlineStat uses stochastic approximation, it will have a keyword argument rate (see this great resource on stochastic approximation algorithms).","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"Consider how weights affect the influence of the next observation on an online mean theta^(t), as many OnlineStats use updates of this form.  A larger weight  gamma_t puts higher influence on the new observation x_t:","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"theta^(t) = (1-gamma_t)theta^(t-1) + gamma_t x_t","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"note: Note\nThe values produced by a Weight must follow two rules:gamma_1 = 1 (guarantees theta^(1) = x_1)\ngamma_t in (0 1) quad forall t  1 (guarantees theta^(t) stays inside a convex space)","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/8075494/57347301-cc7a4200-711f-11e9-86e5-385e4f77f069.png\" style=\"width:400\">","category":"page"},{"location":"weights/#Weight-Types-1","page":"Weights","title":"Weight Types","text":"","category":"section"},{"location":"weights/#","page":"Weights","title":"Weights","text":"EqualWeight\nExponentialWeight\nLearningRate\nLearningRate2\nHarmonicWeight\nMcclainWeight","category":"page"},{"location":"weights/#OnlineStatsBase.EqualWeight","page":"Weights","title":"OnlineStatsBase.EqualWeight","text":"EqualWeight()\n\nEqually weighted observations.\n\nγ(t) = 1  t\n\n\n\n\n\n","category":"type"},{"location":"weights/#OnlineStatsBase.ExponentialWeight","page":"Weights","title":"OnlineStatsBase.ExponentialWeight","text":"ExponentialWeight(λ::Float64)\nExponentialWeight(lookback::Int)\n\nExponentially weighted observations.  The first weight is 1.0 and all else are λ = 2 / (lookback + 1).\n\nγ(t) = λ\n\n\n\n\n\n","category":"type"},{"location":"weights/#OnlineStatsBase.LearningRate","page":"Weights","title":"OnlineStatsBase.LearningRate","text":"LearningRate(r = .6)\n\nSlowly decreasing weight.  Satisfies the standard stochastic approximation assumption  γ(t) =   γ(t)^2   if r  (5 1.\n\nγ(t) = inv(t ^ r)\n\n\n\n\n\n","category":"type"},{"location":"weights/#OnlineStatsBase.LearningRate2","page":"Weights","title":"OnlineStatsBase.LearningRate2","text":"LearningRate2(c = .5)\n\nSlowly decreasing weight.\n\nγ(t) = inv(1 + c * (t - 1))\n\n\n\n\n\n","category":"type"},{"location":"weights/#OnlineStatsBase.HarmonicWeight","page":"Weights","title":"OnlineStatsBase.HarmonicWeight","text":"HarmonicWeight(a = 10.0)\n\nWeight determined by harmonic series.\n\nγ(t) = a  (a + t - 1)\n\n\n\n\n\n","category":"type"},{"location":"weights/#OnlineStatsBase.McclainWeight","page":"Weights","title":"OnlineStatsBase.McclainWeight","text":"McclainWeight(α = .1)\n\nWeight which decreases into a constant.\n\nγ(t) = γ(t-1)  (1 + γ(t-1) - α)\n\n\n\n\n\n","category":"type"},{"location":"weights/#Custom-Weighting-1","page":"Weights","title":"Custom Weighting","text":"","category":"section"},{"location":"weights/#","page":"Weights","title":"Weights","text":"The Weight can be any callable object that receives the number of observations as its argument.  For example:","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"weight = inv will have the same result as weight = EqualWeight().\nweight = x -> x == 1 ? 1.0 : .01 will have the same result as weight = ExponentialWeight(.01)","category":"page"},{"location":"weights/#","page":"Weights","title":"Weights","text":"using OnlineStats # hide\ny = randn(100);\n\nfit!(Mean(weight = EqualWeight()), y)\nfit!(Mean(weight = inv), y)\n\nfit!(Mean(weight = ExponentialWeight(.01)), y)\nfit!(Mean(weight = x -> x == 1 ? 1.0 : .01), y)","category":"page"},{"location":"weights/#Example-of-Weight-Effects-using-Data-with-[Concept-Drift](https://en.wikipedia.org/wiki/Concept_drift)-1","page":"Weights","title":"Example of Weight Effects using Data with Concept Drift","text":"","category":"section"},{"location":"weights/#","page":"Weights","title":"Weights","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/8075494/57347308-d4d27d00-711f-11e9-8fbe-fc4523b96b48.gif\" style=\"width:400\">","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"using OnlineStats","category":"page"},{"location":"howfitworks/#How-fit!-Works-1","page":"How fit! Works","title":"How fit! Works","text":"","category":"section"},{"location":"howfitworks/#Core-Principles-1","page":"How fit! Works","title":"Core Principles","text":"","category":"section"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"Stats are subtypes of OnlineStat{T} where T is the type of a single observation.\nE.g. Mean <: OnlineStat{Number}\nfit!(o::OnlineStat{T}, data::T)\nUpdate o with the single observation data.\nfit!(o::OnlineStat{T}, data::S)\nIterate through data and fit! each item.","category":"page"},{"location":"howfitworks/#Why-is-Fitting-Based-on-Iteration?-1","page":"How fit! Works","title":"Why is Fitting Based on Iteration?","text":"","category":"section"},{"location":"howfitworks/#Reason-1:-OnlineStats-doesn't-make-assumptions-on-the-shape-of-your-data-1","page":"How fit! Works","title":"Reason 1: OnlineStats doesn't make assumptions on the shape of your data","text":"","category":"section"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"Consider CovMatrix, for which a single observation is an AbstractVector, Tuple, or NamedTuple. If I try to update it with a Matrix, it's ambiguous whether I want rows or columns of the matrix to be treated as individual observations.","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"note: Note\nUse eachrow and eachcol (from LinearAlgebra) to choose what to iterate over. For Julia versions less than 1.1, use OnlineStats.eachrow and OnlineStats.eachcol.","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"x = randn(1000, 2)\n\nfit!(CovMatrix(), eachrow(x))\n\nfit!(CovMatrix(), eachcol(x'))","category":"page"},{"location":"howfitworks/#Reason-2:-OnlineStats-works-out-of-the-box-with-many-data-structures-1","page":"How fit! Works","title":"Reason 2: OnlineStats works out-of-the-box with many data structures","text":"","category":"section"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"Tabular data structures such as those in JuliaDB iterate over named tuples of rows, so things like this just work:","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"using JuliaDB\n\nt = table(randn(100), randn(100))\n\nfit!(2Mean(), t)","category":"page"},{"location":"howfitworks/#A-Common-Error-1","page":"How fit! Works","title":"A Common Error","text":"","category":"section"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"Consider the following example:","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"fit!(Mean(), \"asdf\")","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"This causes an error because:","category":"page"},{"location":"howfitworks/#","page":"How fit! Works","title":"How fit! Works","text":"\"asdf\" is not a Number, so OnlineStats attempts to iterate through it\nIterating through \"asdf\" begins with the character 'a'","category":"page"},{"location":"stats_and_models/#Statistics-and-Models-1","page":"Statistics and Models","title":"Statistics and Models","text":"","category":"section"},{"location":"stats_and_models/#Univariate-Statistics-1","page":"Statistics and Models","title":"Univariate Statistics","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nMean Mean\nVariance Variance\nQuantiles Quantile and P2Quantile\nMaximum/Minimum Extrema\nSkewness and kurtosis Moments\nSum Sum","category":"page"},{"location":"stats_and_models/#Time-Series-1","page":"Statistics and Models","title":"Time Series","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nDifference Diff\nLag Lag\nAutocorrelation/autocovariance AutoCov\nTracked history StatLag","category":"page"},{"location":"stats_and_models/#Multivariate-Analysis-1","page":"Statistics and Models","title":"Multivariate Analysis","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nCovariance/correlation matrix CovMatrix\nPrincipal components analysis CovMatrix\nK-means clustering (SGD) KMeans\nMultiple univariate statistics Group","category":"page"},{"location":"stats_and_models/#Nonparametric-Density-Estimation-1","page":"Statistics and Models","title":"Nonparametric Density Estimation","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nHistograms/continuous density Hist and KHist\nApproximate order statistics OrderStats\nCount for each unique value CountMap\nApproximate CDF OrderStats","category":"page"},{"location":"stats_and_models/#Parametric-Density-Estimation-1","page":"Statistics and Models","title":"Parametric Density Estimation","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nBeta FitBeta\nCauchy FitCauchy\nGamma FitGamma\nLogNormal FitLogNormal\nNormal FitNormal\nMultinomial FitMultinomial\nMvNormal FitMvNormal","category":"page"},{"location":"stats_and_models/#Statistical-Learning-1","page":"Statistics and Models","title":"Statistical Learning","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nGLMs with regularization StatLearn\nLogistic regression StatLearn\nLinear SVMs StatLearn\nQuantile regression StatLearn\nAbsolute loss regression StatLearn\nDistance-weighted discrimination StatLearn\nHuber-loss regression StatLearn\nLinear (also ridge) regression LinReg, LinRegBuilder\nDecision Trees FastTree\nRandom Forest FastForest\nNaive Bayes Classifier NBClassifier","category":"page"},{"location":"stats_and_models/#Other-1","page":"Statistics and Models","title":"Other","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nStatistical Bootstrap Bootstrap\nApprox. count of distinct elements HyperLogLog\nReservoir sampling ReservoirSample\nBig Data Viz Partition, IndexedPartition","category":"page"},{"location":"stats_and_models/#Collection-of-Stats-1","page":"Statistics and Models","title":"Collection of Stats","text":"","category":"section"},{"location":"stats_and_models/#","page":"Statistics and Models","title":"Statistics and Models","text":"Statistic/Model OnlineStat\nApply stats to same data stream Series, FTSeries\nApply stats to different data streams Group\nCalculate stat by group GroupBy","category":"page"},{"location":"demos/#Demos-1","page":"Demos","title":"Demos","text":"","category":"section"},{"location":"demos/#","page":"Demos","title":"Demos","text":"A collection of jupyter notebooks are hosted at https://github.com/joshday/OnlineStatsDemos.  ","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"import Pkg, Random\nusing Dates\nPkg.add(\"GR\")\nPkg.add(\"Plots\")\nENV[\"GKSwstype\"] = \"100\"\nENV[\"GKS_ENCODING\"]=\"utf8\"\nusing OnlineStats\nusing Plots\nusing PlotThemes\nRandom.seed!(1234)\ngr()\ntheme(:bright)","category":"page"},{"location":"dataviz/#Data-Viz-1","page":"Data Viz","title":"Data Viz","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"note: Note\nEach example plots one million data points.","category":"page"},{"location":"dataviz/#Partitions-1","page":"Data Viz","title":"Partitions","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"The Partition type summarizes sections of a data stream using any OnlineStat, and is therefore extremely useful in visualizing huge datasets, as summaries are plotted rather than every single observation.","category":"page"},{"location":"dataviz/#Continuous-Data-1","page":"Data Viz","title":"Continuous Data","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"y = cumsum(randn(10^6)) + 100randn(10^6)\n\no = Partition(KHist(10))\n\nfit!(o, y)\n\nplot(o)\nsavefig(\"partition_hist.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"o = Partition(Series(Mean(), Extrema()))\n\nfit!(o, y)\n\nplot(o)\nsavefig(\"partition_mean_ex.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#Categorical-Data-1","page":"Data Viz","title":"Categorical Data","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"y = rand([\"a\", \"a\", \"b\", \"c\"], 10^6)\n\no = Partition(CountMap(String), 75)\n\nfit!(o, y)\n\nplot(o)\nsavefig(\"partition_countmap.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#Indexed-Partitions-1","page":"Data Viz","title":"Indexed Partitions","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"The Partition type can only track the number of observations in the x-axis.  If you wish to plot one variable against another, you can use an IndexedPartition.","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"x = randn(10^6)\ny = x + randn(10^6)\n\no = fit!(IndexedPartition(Float64, KHist(40), 40), zip(x, y))\n\nplot(o)\nsavefig(\"indexpart2.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"x = rand(10^6)\ny = rand(1:5, 10^6)\n\no = fit!(IndexedPartition(Float64, CountMap(Int)), zip(x,y))\n\nplot(o, xlab = \"X\", ylab = \"Y\")\nsavefig(\"indexpart4.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"x = rand(1:1000, 10^6)\ny = x .+ 30randn(10^6)\n\no = fit!(IndexedPartition(Int, KHist(20)), zip(x,y))\n\nplot(o)\nsavefig(\"indexpartequal.png\"); nothing # hide\n","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#Histograms-1","page":"Data Viz","title":"Histograms","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"s = fit!(Series(KHist(25), Hist(-5:.2:5)), randn(10^6))\nplot(s)\nsavefig(\"plot_series.png\") # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#Approximate-CDF-1","page":"Data Viz","title":"Approximate CDF","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"o = fit!(OrderStats(1000), randn(10^6))\n\nplot(o)","category":"page"},{"location":"dataviz/#Mosaic-Plots-1","page":"Data Viz","title":"Mosaic Plots","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"The Mosaic type allows you to plot the relationship between two categorical variables. It is typically more useful than a bar plot, as class probabilities are given by the horizontal widths.","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"using RDatasets \nt = dataset(\"ggplot2\", \"diamonds\")\n\no = Mosaic(eltype(t.Cut), eltype(t.Color))\n\nfit!(o, zip(t.Cut, t.Color))\n\nplot(o, legendtitle=\"Survived\", xlabel=\"Age\")\nsavefig(\"mosaic.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#HeatMap-1","page":"Data Viz","title":"HeatMap","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"o = HeatMap(-5:.1:5, -0:.1:10)\n\nx, y = randn(10^6), 5 .+ randn(10^6)\n\nfit!(o, zip(x, y))\n\nplot(o)\nsavefig(\"heatmap.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"x, y = randn(10^6), randn(10^6)\n\no = HeatMap(zip(x, y), 200)  # use 200 bins in both dimensions\n\nplot(o, aspect_ratio=:equal)\nsavefig(\"heatmap2.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"dataviz/#Naive-Bayes-Classifier-1","page":"Data Viz","title":"Naive Bayes Classifier","text":"","category":"section"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"The NBClassifier type stores conditional histograms of the predictor variables, allowing you to plot approximate \"group by\" distributions:","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"# make data\nx = randn(10^6, 5)\ny = x * [1,3,5,7,9] .> 0\n\no = NBClassifier(5, Bool)  # 5 predictors with Boolean categories\nfit!(o, zip(eachrow(x), y))\nplot(o)\nsavefig(\"nbclassifier.png\"); nothing # hide","category":"page"},{"location":"dataviz/#","page":"Data Viz","title":"Data Viz","text":"(Image: )","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"using Pkg\nPkg.add(\"GR\")\nPkg.add(\"Plots\")\nENV[\"GKSwstype\"] = \"100\"\nENV[\"GKS_ENCODING\"]=\"utf8\"","category":"page"},{"location":"bigdata/#Big-Data-1","page":"Big Data","title":"Big Data","text":"","category":"section"},{"location":"bigdata/#OnlineStats-CSV-1","page":"Big Data","title":"OnlineStats + CSV","text":"","category":"section"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"The CSV package offers a very memory-efficient way of iterating through the rows of a (possibly larger-than-memory) CSV file.","category":"page"},{"location":"bigdata/#Example-1","page":"Big Data","title":"Example","text":"","category":"section"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"Here is a toy example (Iris dataset) of how to iterate through the rows of a CSV file one-by-one and calculate histograms grouped by another variable.","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"using OnlineStats, CSV, Plots\n\nurl = \"https://gist.githubusercontent.com/joshday/df7bdaa1d58b398592e7656395de6335/raw/5a1c83f498f8ca7e25ff2372340e44b3389be9b1/iris.csv\"\n\nrows = CSV.Rows(download(url); allowmissing=:none)\n\no = GroupBy(String, Group([Hist(0:.2:8) for _ in 1:4]...))\n\nvars = [:sepal_length, :sepal_width, :petal_length, :petal_width]\n\nx = zeros(4)  # create buffer for storing rows\n\nfor row in rows\n    map!(x -> parse(Float64, getproperty(row, x)), x, vars)\n    fit!(o, (row.variety, x))\nend\n\nplot(o[\"Versicolor\"], label=permutedims(vars), xlim=(0,8))\nsavefig(\"versicolor.png\") # hide","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"(Image: )","category":"page"},{"location":"bigdata/#Distributed-Parallelism-1","page":"Big Data","title":"Distributed Parallelism","text":"","category":"section"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"OnlineStats can be merged together to facilitate Embarassingly parallel computations.  For example, merging in OnlineStats is used under the hood by JuliaDB to run analytics in parallel.","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"note: Note\nIn general, fit! is a cheaper operation than merge!.","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"warn: Warn\nNot every OnlineStat can be merged.  In these cases, OnlineStats either uses an approximation or provides a warning that no merging occurred.","category":"page"},{"location":"bigdata/#Examples-1","page":"Big Data","title":"Examples","text":"","category":"section"},{"location":"bigdata/#Simplified-(Not-Actually-in-Parallel)-1","page":"Big Data","title":"Simplified (Not Actually in Parallel)","text":"","category":"section"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"y1 = randn(10_000)\ny2 = randn(10_000)\ny3 = randn(10_000)\n\ns1 = Series(Mean(), Variance(), KHist(20))\ns2 = Series(Mean(), Variance(), KHist(20))\ns3 = Series(Mean(), Variance(), KHist(20))\n\nfit!(s1, y1)\nfit!(s2, y2)\nfit!(s3, y3)\n\nmerge!(s1, s2)  # merge information from s2 into s1\nmerge!(s1, s3)  # merge information from s3 into s1","category":"page"},{"location":"bigdata/#In-Parallel-1","page":"Big Data","title":"In Parallel","text":"","category":"section"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"using Distributed\naddprocs(3)\n@everywhere using OnlineStats\n\ns = @distributed merge for i in 1:3\n    o = Series(Mean(), Variance(), KHist(20))\n    fit!(o, randn(10_000))\nend","category":"page"},{"location":"bigdata/#","page":"Big Data","title":"Big Data","text":"<img src = \"https://user-images.githubusercontent.com/8075494/57345083-95079780-7117-11e9-81bf-71b0469f04c7.png\" style=\"width:400px\">","category":"page"},{"location":"#","page":"Home","title":"Home","text":"<div style=\"width:100%; height:150px;border-width:1px;border-style:solid;padding-top:25px;\n        border-color:#000;border-radius:10px;text-align:center;background-color:#209cee;\n        color:#FFF\">\n    <h3 style=\"color:white\">Star us on GitHub!</h3>\n    <a class=\"github-button\" href=\"https://github.com/joshday/OnlineStats.jl\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star joshday/OnlineStats.jl on GitHub\" style=\"margin:auto\">Star</a>\n    <script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n</div>","category":"page"},{"location":"#Home-1","page":"Home","title":"Home","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"OnlineStats is a Julia package for statistical analysis with algorithms that run both online and in parallel.  Online algorithms are well suited for streaming data or when data is too large to hold in memory.  Observations are processed one at a time and all algorithms use O(1) memory.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"import Pkg\nPkg.add(\"OnlineStats\")","category":"page"},{"location":"#Basics-1","page":"Home","title":"Basics","text":"","category":"section"},{"location":"#Every-stat-is-:-OnlineStat{T}-1","page":"Home","title":"Every stat is <: OnlineStat{T}","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"(where T is the type of a single observation)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using OnlineStats\nm = Mean()\nsupertype(Mean)","category":"page"},{"location":"#Stats-can-be-updated-1","page":"Home","title":"Stats can be updated","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nfit! can be used to update the stat with a single observation or multiple observations: fit!(stat::OnlineStat{T}, y::S) will iterate through y and fit! each element if T != S.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"y = randn(100);\nfit!(m, y)","category":"page"},{"location":"#Stats-can-be-merged-1","page":"Home","title":"Stats can be merged","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"y2 = randn(100);\nm2 = fit!(Mean(), y2)\nmerge!(m, m2)","category":"page"},{"location":"#Stats-have-a-value-1","page":"Home","title":"Stats have a value","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"value(m)","category":"page"},{"location":"#Collections-of-Stats-1","page":"Home","title":"Collections of Stats","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"<img src=\"https://user-images.githubusercontent.com/8075494/57342826-bf088c00-710e-11e9-9ac0-f3c1e5aa7a7d.png\" style=\"width:400px\">","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using OnlineStats","category":"page"},{"location":"#Series-1","page":"Home","title":"Series","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A Series tracks stats that should be applied to the same data stream.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"y = rand(1000)\ns = Series(Mean(), Variance())\nfit!(s, y)","category":"page"},{"location":"#FTSeries-1","page":"Home","title":"FTSeries","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"An FTSeries tracks stats that should be applied to the same data stream, but filters and transforms (hence FT) the input data before it is sent to its stats.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"s = FTSeries(Mean(), Variance(); filter = x->true, transform = abs)\nfit!(s, -y)","category":"page"},{"location":"#Group-1","page":"Home","title":"Group","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A Group tracks stats that should be applied to different data streams.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"g = Group(Mean(), CountMap(Bool))\nitr = zip(randn(100), rand(Bool, 100))\nfit!(g, itr)","category":"page"},{"location":"#Additional-Resources-1","page":"Home","title":"Additional Resources","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"OnlineStats Demos","category":"page"}]
}
